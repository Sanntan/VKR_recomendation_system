# Нагрузочное тестирование телеграм-бота

Этот документ описывает устройство скрипта [`scripts/load_test_bot.py`](../scripts/load_test_bot.py),
процедуру запуска нагрузочного тестирования, формат отчётных файлов и способы
их интерпретации.

## Общая архитектура скрипта

Скрипт поддерживает два режима работы:

* **`synthetic`** — автономный стресс-тест без обращений к серверам Telegram.
* **`live`** — сценарии отправляются в реальные чаты через Bot API (требуется
  действительный токен и список `chat_id`).

Основные компоненты:

1. **`build_application`** из `src/bot/main.py`
   создаёт `Application` с теми же обработчиками, что и в боевой версии бота.
2. **`FakeBotAPIRequest`** наследуется от `telegram.request.BaseRequest` и
   перехватывает все запросы к Bot API. Вместо HTTP-вызовов он возвращает
   синтетические ответы, что позволяет запускать тест без сети и внешних
   зависимостей. Дополнительно можно задать искусственную задержку с помощью
   параметра `--transport-delay`.
3. **`ScenarioFactory`** генерирует последовательности объектов `Update` для
   эмуляции поведения пользователя. Все валидные ветки отправляют e-mail
   `stud0000286472@study.utmn.ru` сразу после `/start`, что гарантирует
   прохождение текущей валидации. После авторизации каждый сценарий обязательно
   проходит по вкладкам главного меню, рекомендаций, поиска и обратной связи, а
   затем отправляет текст обратной связи внутри соответствующего раздела. В
   `live`-режиме навигация имитируется текстовыми командами, в синтетическом —
   настоящими callback-запросами. Доступные сценарии:

   * `full` — «золотой путь»: `/start` → e-mail → обход всех вкладок → отзыв →
     дополнительные текстовые проверки;
   * `simple` — только сообщения (подходит для `live`), но с обязательным
     прохождением навигации и отзывом;
   * `text_storm` — серия из 10 тематических сообщений, после чего выполняется
     стандартная навигация и обратная связь;
   * `menu_spam` — интенсивное «прокликивание» меню в дополнение к базовой
     навигации (только синтетический режим);
   * `feedback_loop` — многократное повторное открытие раздела обратной связи с
     последовательными сообщениями от `stud0000286472@study.utmn.ru`.

   Доля корректных/некорректных e-mail управляется параметром
   `--valid-email-ratio`.
4. **`process_update`** и **`run_load_test`** распараллеливают обработку
   обновлений, используя семафор для ограничения одновременных задач,
   автоматический rate limiter для `live`-режима и повторные попытки при
   ответах `RetryAfter`/`TimedOut` от Bot API.
5. **`LoadTestMetrics`** фиксирует задержки обработки, группирует их по типам
   (`message`, `callback`), считает квантили и собирает ошибки. Итоговые данные
   сохраняются в JSON, а при указании `--raw-metrics-file` — ещё и в CSV.

## Алгоритм работы

1. Скрипт разбирает аргументы командной строки и настраивает логирование в
   файл `logs/load_test.log` (значение можно изменить флагом `--log-file`).
2. Создаётся приложение Telegram Bot API. В режиме `synthetic` используется
   поддельный транспорт и фиксированный токен (если не указан собственный),
   в `live` — стандартный транспорт библиотеки и реальный токен бота.
3. Для каждого виртуального пользователя (определяется `--users`) сценарий
   повторяется до тех пор, пока не выполнены оба условия: достигнута минимальная
   длительность теста (`--min-duration`, по умолчанию 600 секунд, то есть 10
   минут) либо пользователь не прервал выполнение `KeyboardInterrupt`, и
   одновременно отработано заданное число итераций (`--iterations`). Для
   отладки можно снять ограничение, добавив флаг `--allow-short-runs`.
4. Все обновления отправляются в очередь `Application.process_update`, а
   фактическое количество одновременно исполняемых задач ограничивает флаг
   `--concurrency`. В `live`-режиме каждое обновление дополнительно проходит
   через rate limiter (`--live-global-rate`, `--live-chat-rate`) и может быть
   повторно отправлено при сетевых ошибках `RetryAfter`/`TimedOut`.
5. После завершения теста или прерывания метрики выгружаются в JSON
   (`--metrics-file`) и, при необходимости, в CSV (`--raw-metrics-file`). Для
   профилей с несколькими фазами основной JSON содержит агрегированный отчёт по
   всем этапам, а подробные файлы создаются с суффиксами `_warmup`, `_scale_up`
   и т. д.

## Аргументы командной строки

| Параметр | По умолчанию | Описание |
| --- | --- | --- |
| `--users` | `50` | Количество виртуальных пользователей. |
| `--iterations` | `5` | Сколько раз каждый пользователь повторяет сценарий. |
| `--concurrency` | `20` | Максимальное число одновременных обновлений. |
| `--valid-email-ratio` | `0.8` | Доля корректных e-mail среди всех пользователей. |
| `--inter-update-delay` | `0.0` | Задержка (секунды) между обновлениями одного пользователя. |
| `--transport-delay` | `0.0` | Искусственная задержка внутри `FakeBotAPIRequest` (только `synthetic`). |
| `--log-file` | `logs/load_test.log` | Путь к файлу с логами выполнения. |
| `--metrics-file` | `logs/load_test_metrics.json` | Путь к JSON с агрегированными метриками. |
| `--raw-metrics-file` | `—` | При указании сохраняет CSV с покадровыми задержками. |
| `--token` | значение `BOT_TOKEN` из окружения или `TEST:TOKEN` | Токен бота. |
| `--log-level` | `INFO` | Уровень логирования (`DEBUG`, `INFO`, `WARNING`, `ERROR`). |
| `--seed` | `—` | Фиксированный seed генератора случайных чисел для повторяемости сценариев. |
| `--mode` | `synthetic` | Режим тестирования: `synthetic` или `live`. |
| `--scenario` | `full` | Тип сценария: `full`, `simple`, `text_storm`, `menu_spam`, `feedback_loop`. |
| `--profile` | `single` | Преднастроенный профиль нагрузки (`single`, `stress`, `spike`, `soak`). |
| `--chat-ids` | `—` | Список `chat_id` через запятую для режима `live`. |
| `--auto-discover-chat-ids` | `false` | Автоматически пытается извлечь `chat_id` из последних `getUpdates` (только `live`). |
| `--discover-limit` | `20` | Сколько обновлений считывать во время автообнаружения `chat_id`. |
| `--min-duration` | `600.0` | Минимальная длительность теста (секунды); значение меньше 600 применяется только при `--allow-short-runs`. |
| `--max-retries` | `3` | Число повторных попыток при ошибках Bot API. |
| `--live-global-rate` | `25.0` | Глобальный лимит запросов в секунду в `live`-режиме (`0` — без ограничения). |
| `--live-chat-rate` | `1.0` | Лимит запросов в секунду на один чат (`0` — без ограничения). |
| `--allow-short-runs` | `false` | Разрешить длительность прогона меньше 600 секунд (режим отладки). |
| `--suite` | `none` | Запустить готовый набор прогонов (`stress_all`). |

### Особенности `live`-режима

* Перед запуском убедитесь, что у бота есть как минимум один активный чат:
  отправьте `/start`, затем используйте `--auto-discover-chat-ids` или передайте
  идентификатор вручную через `--chat-ids`.
* Лимиты `--live-global-rate` и `--live-chat-rate` помогают избежать ошибок
  `Flood control exceeded` (HTTP 429). При получении `RetryAfter` скрипт ждёт
  указанный интервал, делает повтор до `--max-retries` и фиксирует событие в
  отчёте.
* Тайм-ауты `TimedOut` и другие сетевые ошибки автоматически повторяются с
  экспоненциальной паузой. Если после максимума попыток ошибка сохраняется, она
  попадает в раздел `error_messages` итогового JSON и фиксируется в отдельном
  файле ошибок.
* Нагрузочное тестирование длится не менее `--min-duration` секунд (по умолчанию
  600). После истечения времени можно прервать скрипт `Ctrl+C` — он корректно
  соберёт и сохранит накопленные метрики и вспомогательные отчёты.

## Пример запуска

```bash
python scripts/load_test_bot.py \
  --users 100 \
  --iterations 3 \
  --concurrency 40 \
  --profile stress \
  --scenario menu_spam \
  --valid-email-ratio 0.7 \
  --inter-update-delay 0.02 \
  --transport-delay 0.01 \
  --log-level INFO \
  --log-file logs/load_test.log \
  --metrics-file logs/summary.json \
  --raw-metrics-file logs/raw.csv
```

При выборе профиля `stress` скрипт выполнит четыре фазы с нарастающей
нагрузкой, а отчёты по каждой фазе будут сохранены в файлах с суффиксом
`_<label>`. Дополнительно появятся файлы `*_timeline.csv`, `*_histogram.json`,
`*_errors.json` и `*_per_type.json` с расширенной статистикой.

### Преднастроенный набор стресс-прогонов

Флаг `--suite stress_all` запускает стресс-профиль последовательно для всех
поддерживаемых сценариев и обоих режимов. Для синтетических прогонов выполняются
`full`, `menu_spam`, `feedback_loop` и `text_storm`, а для `live` — `simple` и
`text_storm`. Каждый прогон длится не менее 10 минут (или больше, если указано
`--min-duration`).

Пример команды для запуска полного набора с реальным Bot API (не забудьте
указать `--chat-ids` или `--auto-discover-chat-ids`):

```bash
python scripts/load_test_bot.py \
  --suite stress_all \
  --users 50 \
  --iterations 3 \
  --concurrency 25 \
  --log-level INFO \
  --metrics-file logs/stress_suite.json \
  --raw-metrics-file logs/stress_suite_raw.csv \
  --chat-ids <CHAT_ID> \
  --token $BOT_TOKEN
```

Скрипт создаст отдельные лог-файлы и набор метрик для каждого сценария и режима,
а итоговый отчёт сохранит в `logs/stress_suite.json`.

## Преднастроенные профили нагрузки

Флаг `--profile` выбирает последовательность фаз и их параметры. Каждая фаза
может изменять количество пользователей, итераций, уровень параллелизма,
сценарий и задержки. Доступны четыре профиля:

* **`single`** — один прогон с указанными параметрами.
* **`stress`** — «прогрев» → базовый уровень → `scale_up` → `breaking_point`.
  В последних двух фазах нагрузка существенно возрастает; в синтетическом
  режиме используется сценарий `menu_spam`, а в live — `text_storm`.
* **`spike`** — базовый прогон, резкий всплеск с очень высокой
  конкурентностью, затем восстановление для оценки поведения после скачка.
* **`soak`** — длительный «soak-тест» с большим числом итераций и финальной
  фазой `chaos`, где повышается доля некорректных e-mail и бот получает серийные
  повторяющиеся запросы.

В многофазном профиле для каждой фазы создаётся отдельный файл метрик и,
при указании `--raw-metrics-file`, отдельный CSV с сырыми задержками. Основной
файл, переданный в `--metrics-file`, содержит агрегированный отчёт вида:

```json
{
  "profile": "stress",
  "phases": [
    {
      "label": "warmup",
      "users": 25,
      "concurrency": 10,
      "scenario": "full",
      "summary": { "total_updates": 123, "...": "..." },
      "metrics_file": "logs/summary_warmup.json",
      "raw_metrics_file": "logs/raw_warmup.csv"
    },
    {
      "label": "breaking_point",
      "users": 200,
      "concurrency": 120,
      "scenario": "menu_spam",
      "summary": { "total_updates": 987, "...": "..." }
    }
  ]
}
```

## Формат отчётных файлов

### CSV с сырыми задержками (`--raw-metrics-file`)

Файл содержит три столбца:

- `update_index` — порядковый номер обработанного обновления;
- `type` — тип обновления (`message`, `callback`, `other`);
- `latency_ms` — длительность обработки в миллисекундах.

Пример строк:

```
update_index,type,latency_ms
1,message,0.206
2,message,0.347
3,callback,0.192
...
```

### Дополнительные артефакты

При каждом прогоне автоматически формируются дополнительные файлы:

* `*_timeline.csv` — хронологический список обработанных обновлений с отметками
  времени, длительностью и числом попыток;
* `*_histogram.json` — гистограмма задержек (10 равномерных корзин);
* `*_per_type.json` — количество обновлений по типам и соответствующие
  квантильные метрики;
* `*_errors.json` — словарь ошибок и их частота.

Сводный JSON (`--metrics-file`) теперь содержит также информацию о средней и
максимальной численности повторов (`attempts`).

Каждая строка соответствует одному вызову `Application.process_update`. По
этому файлу удобно строить графики распределения задержек и находить выбросы.

### JSON со сводными метриками (`--metrics-file`)

В JSON записывается словарь со следующими полями:

- `total_updates` — общее количество обработанных обновлений;
- `errors` — число исключений во время обработки;
- `duration_sec` — суммарное время выполнения теста;
- `throughput_rps` — пропускная способность (обновлений в секунду);
- `latency_overall` — агрегированные метрики задержек по всем обновлениям;
- `latency_by_type` — такие же метрики, но для отдельных типов (`message`, `callback`);
- `error_messages` — список текстов исключений (если были).

Для предоставленного примера:

```json
{
  "total_updates": 26,
  "errors": 0,
  "duration_sec": 0.0052,
  "throughput_rps": 5004.62,
  "latency_overall": {
    "avg": 0.000128,
    "median": 0.000120,
    "p95": 0.000203,
    "p99": 0.000312
  },
  "latency_by_type": {
    "message": {
      "avg": 0.000172,
      "median": 0.000143,
      "p95": 0.000312,
      "p99": 0.000340
    },
    "callback": {
      "avg": 0.000115,
      "median": 0.000120,
      "p95": 0.000150,
      "p99": 0.000184
    }
  },
  "error_messages": []
}
```

> Примечание. Для длительных `live`-прогонов поле `duration_sec` будет близко к
> значению `--min-duration`, а `throughput_rps` — ниже из-за встроенного rate
> limiter и повторов после ответов Bot API.

Такие значения говорят о том, что тест завершился без ошибок, обработал 26
обновлений примерно за 5 мс и показал условную пропускную способность ~5000
обновлений в секунду. Задержки находятся в диапазоне 0.09–0.34 мс, причём
сообщения обрабатываются чуть дольше, чем callback-запросы (что логично из-за
валидации e-mail и переходов состояний).

При использовании профилей `stress`, `spike` или `soak` агрегированный файл
(`--metrics-file`) будет содержать список фаз с ссылками на отдельные JSON/CSV
для каждой из них.

### Лог-файл (`--log-file`)

Логи записываются одновременно в консоль и в указанный файл. Если файл пустой,
значит в ходе теста не возникло сообщений на выбранном уровне логирования.
Чтобы увидеть более подробные сообщения, запустите тест с `--log-level DEBUG`.

## Рекомендации по анализу

1. **Сравнивайте метрики разных прогонов.** Фиксируйте `--seed`, чтобы сценарии
   были сопоставимы, и варьируйте параметры нагрузки.
2. **Используйте CSV для построения графиков.** Набросьте гистограммы или
   временные ряды по `latency_ms`, чтобы заметить «хвосты» распределения.
3. **Имитируйте сетевые задержки.** Параметр `--transport-delay` доступен в
   режиме `synthetic` и помогает оценить поведение бота при медленном соединении.
4. **Собирайте логи ошибок.** При появлении записей в `error_messages`
   сопоставьте их с соответствующими строками в CSV и записями журнала.

## Завершение теста

Скрипт сам корректно завершает приложение Telegram (`application.shutdown()`),
поэтому дополнительных действий не требуется. Все файлы отчётов остаются в
указанных путях и готовы к дальнейшему анализу.

## Работа в режиме live

1. Добавьте токен бота в файл `.env` (`BOT_TOKEN=...`) или передайте через
   переменную окружения/флаг `--token`.
2. Определите список тестовых чатов и передайте их идентификаторы с помощью
  `--chat-ids`. Допустимо указать несколько `chat_id`, разделённых запятыми.
  Для индивидуального тестирования достаточно вашего личного диалога с ботом.
  Узнать идентификатор можно двумя способами:

  * автоматическое обнаружение флагом `--auto-discover-chat-ids` (перед запуском
    отправьте боту сообщение `/start`, чтобы обновление попало в очередь);
  * вручную — например, переслать любое сообщение из чата сервису
    [@userinfobot](https://t.me/userinfobot) или посмотреть `chat.id` в логах
    при запуске с `--log-level DEBUG`.

3. Выберите сценарий `simple` или `text_storm` (рекомендуется по умолчанию;
  сценарии `full` и `menu_spam` будут автоматически заменены на `text_storm`,
  поскольку синтетические callback-запросы невалидны для реального Bot API).
4. Запустите тест с `--mode live`. Ответы бота будут отправляться в указанные
  чаты, а задержки и логи будут собраны в тех же файлах, что и в режиме
  `synthetic`.

Если включено автообнаружение, скрипт выведет список найденных `chat_id` в
логах. При повторном запуске их можно указать явно через `--chat-ids`, чтобы
избежать повторного запроса к `getUpdates`.

# Нагрузочное тестирование базы данных

Скрипт [`scripts/load_test_db.py`](../scripts/load_test_db.py) предназначен для
нагрузочного тестирования слоя работы с Supabase/PostgreSQL. Он использует
существующие SQLAlchemy-модели и функции из `src/core/database/crud`, поэтому
нагрузка максимально приближена к реальным путям приложения.

## Архитектура и сценарии

1. **Предзагрузка справочников.** Перед стартом теста скрипт загружает до
   `--prefetch-limit` записей из таблиц `students`, `events` и `feedback`. Если
   не удаётся найти хотя бы одного студента или событие, выполнение прекращается
   с понятной ошибкой.
2. **SharedState.** Для каждого теста создаётся объект `SharedState`, который
   хранит предзагруженные идентификаторы и список отзывов, созданных во время
   теста. Он же отвечает за последующую очистку (`--no-cleanup` отключает её).
3. **Набор операций.** В зависимости от выбранного профиля выполняются
   комбинированные сценарии:

   * чтение карточки студента по `participant_id` (`students.get_student_by_participant_id`);
   * запрос рекомендаций для студента (`recommendations.get_recommendations_for_student`);
   * выборка витрины событий `SELECT id, title FROM events LIMIT N`;
   * чтение отзывов студента (`feedback.get_feedbacks_by_student`);
   * создание нового отзыва с типовым комментарием;
   * обновление случайного отзыва.

   При отсутствии отзывов операции чтения/обновления помечаются как пропущенные
   (`skipped`), но не влияют на общую статистику ошибок. Повторные попытки при
   транзиентных ошибках (`OperationalError`, `InterfaceError`) выполняются с
   линейной задержкой `--backoff`.
4. **Воркеры.** Каждый воркер получает собственный генератор случайных чисел и
   до истечения `--duration` (или сигнала `Ctrl+C`) случайно выбирает операции в
   соответствии с весами выбранного профиля (`read-heavy`, `write-heavy`,
   `mixed`). Все вызовы к БД выполняются внутри `asyncio.to_thread`, поэтому
   можно безопасно масштабировать число воркеров до десятков параллельных
   соединений.
5. **Метрики.** Результаты складываются в очередь, а отдельный потребитель
   формирует `LoadTestMetrics`: суммарное число операций, попытки, успехи,
   пропуски, ошибки и квантили задержек как в целом, так и по отдельным
   операциям.

Минимальная длительность по умолчанию — 600 секунд (10 минут). Для отладки можно
использовать `--allow-short-runs`, но в CI/боевых сценариях рекомендуется
оставлять ограничение.

## Аргументы командной строки

| Параметр | По умолчанию | Описание |
| --- | --- | --- |
| `--duration` | `600.0` | Желаемая длительность теста в секундах. |
| `--min-duration` | `600.0` | Минимальная длительность, применяется если не указано `--allow-short-runs`. |
| `--concurrency` | `16` | Количество параллельных воркеров (подключений к БД). |
| `--profile` | `mixed` | Профиль нагрузки: `read-heavy`, `write-heavy`, `mixed`. |
| `--prefetch-limit` | `2000` | Сколько записей загрузить из справочников перед стартом. |
| `--max-retries` | `3` | Число повторов при транзиентных ошибках. |
| `--backoff` | `0.5` | Базовая задержка (сек) между повторами. |
| `--log-dir` | `logs/db` | Каталог, где создаётся подпапка `db_load_<timestamp>`. |
| `--raw-metrics-file` | `—` | Необязательный путь к CSV; без флага файл создаётся внутри папки запуска. |
| `--summary-file` | `—` | Путь к сводному JSON. |
| `--per-type-file` | `—` | JSON со статистикой по типам операций (`read`/`write`). |
| `--timeline-file` | `—` | NDJSON с временной шкалой операций. |
| `--errors-file` | `—` | NDJSON с ошибками и количеством попыток. |
| `--no-cleanup` | `false` | Если указан, оставляет созданные отзывы в базе. |
| `--seed` | `—` | Фиксированный seed генератора случайных чисел. |
| `--log-level` | `INFO` | Уровень логирования. |
| `--allow-short-runs` | `false` | Разрешить длительность ниже `--min-duration`. |

## Логирование и отчёты

Каждый запуск формирует отдельную директорию `logs/db/db_load_<timestamp>/` с
набором файлов:

* `run.log` — полный журнал выполнения, включая повторы и сообщения о
  пропущенных операциях;
* `operations.csv` — временные метки, латентность, число попыток и признак
  `skipped` для каждой операции;
* `summary.json` — агрегированные показатели (через `LoadTestMetrics.summary()`);
* `per_type.json` — количество успешных/ошибочных операций по типам (`read`,
  `write`);
* `timeline.ndjson` — последовательность операций с ISO-таймстампами (удобно
  для построения графиков);
* `errors.ndjson` — подробности по ошибкам и числу попыток; при отсутствующих
  ошибках файл пустой.

При передаче явных путей через `--raw-metrics-file` и другие флаги файлы будут
созданы по указанным адресам (каталоги создаются автоматически). После выгрузки
метрик выполняется очистка всех отзывов, созданных во время теста, если не
указан `--no-cleanup`.

## Пример запуска

```bash
python scripts/load_test_db.py \
  --profile mixed \
  --concurrency 24 \
  --duration 900 \
  --log-level INFO \
  --summary-file logs/db/latest_summary.json \
  --raw-metrics-file logs/db/latest_operations.csv
```

Команда проведёт 15-минутный прогон (900 секунд) с 24 воркерами, сохранит
итоговый отчёт в `logs/db/latest_summary.json`, а детальный CSV — в
`logs/db/latest_operations.csv`. При необходимости можно остановить тест
`Ctrl+C`: скрипт корректно завершит воркеров, выгрузит накопленные метрики и
выполнит очистку временных отзывов.
