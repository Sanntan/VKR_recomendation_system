# Нагрузочное тестирование телеграм-бота

Этот документ описывает устройство скрипта [`scripts/load_test_bot.py`](../scripts/load_test_bot.py),
процедуру запуска нагрузочного тестирования, формат отчётных файлов и способы
их интерпретации.

## Общая архитектура скрипта

Скрипт поддерживает два режима работы:

* **`synthetic`** — автономный стресс-тест без обращений к серверам Telegram.
* **`live`** — сценарии отправляются в реальные чаты через Bot API (требуется
  действительный токен и список `chat_id`).

Основные компоненты:

1. **`build_application`** из `src/bot/main.py`
   создаёт `Application` с теми же обработчиками, что и в боевой версии бота.
2. **`FakeBotAPIRequest`** наследуется от `telegram.request.BaseRequest` и
   перехватывает все запросы к Bot API. Вместо HTTP-вызовов он возвращает
   синтетические ответы, что позволяет запускать тест без сети и внешних
   зависимостей. Дополнительно можно задать искусственную задержку с помощью
   параметра `--transport-delay`.
3. **`ScenarioFactory`** генерирует последовательности объектов `Update` для
   эмуляции поведения пользователя. Все валидные ветки отправляют e-mail
   `stud0000286472@study.utmn.ru`, что соответствует требованиям текущей
   бизнес-логики. Доступные сценарии:

   * `full` — путь `/start` → ввод e-mail → переходы по кнопкам меню и
     отправка обратной связи;
   * `simple` — только текстовые сообщения, подходит для `live`-режима;
   * `text_storm` — серия из десятка сообщений с вопросами, позволяющая проверить
     устойчивость обработчиков текста;
   * `menu_spam` — интенсивное «прокликивание» всех кнопок меню, доступно
     только в синтетическом режиме;
   * `feedback_loop` — циклический переход в раздел обратной связи с серией
     сообщений и возвратом в главное меню (для синтетических прогонов).

   Доля корректных/некорректных e-mail управляется параметром
   `--valid-email-ratio`.
4. **`process_update`** и **`run_load_test`** распараллеливают обработку
   обновлений, используя семафор для ограничения одновременных задач,
   автоматический rate limiter для `live`-режима и повторные попытки при
   ответах `RetryAfter`/`TimedOut` от Bot API.
5. **`LoadTestMetrics`** фиксирует задержки обработки, группирует их по типам
   (`message`, `callback`), считает квантили и собирает ошибки. Итоговые данные
   сохраняются в JSON, а при указании `--raw-metrics-file` — ещё и в CSV.

## Алгоритм работы

1. Скрипт разбирает аргументы командной строки и настраивает логирование в
   файл `logs/load_test.log` (значение можно изменить флагом `--log-file`).
2. Создаётся приложение Telegram Bot API. В режиме `synthetic` используется
   поддельный транспорт и фиксированный токен (если не указан собственный),
   в `live` — стандартный транспорт библиотеки и реальный токен бота.
3. Для каждого виртуального пользователя (определяется `--users`) сценарий
   повторяется до тех пор, пока не выполнены оба условия: достигнута минимальная
   длительность теста (`--min-duration`, по умолчанию 300 секунд) или получен
   сигнал `KeyboardInterrupt`, и выполнено указанное число итераций
   (`--iterations`).
4. Все обновления отправляются в очередь `Application.process_update`, а
   фактическое количество одновременно исполняемых задач ограничивает флаг
   `--concurrency`. В `live`-режиме каждое обновление дополнительно проходит
   через rate limiter (`--live-global-rate`, `--live-chat-rate`) и может быть
   повторно отправлено при сетевых ошибках `RetryAfter`/`TimedOut`.
5. После завершения теста или прерывания метрики выгружаются в JSON
   (`--metrics-file`) и, при необходимости, в CSV (`--raw-metrics-file`). Для
   профилей с несколькими фазами основной JSON содержит агрегированный отчёт по
   всем этапам, а подробные файлы создаются с суффиксами `_warmup`, `_scale_up`
   и т. д.

## Аргументы командной строки

| Параметр | По умолчанию | Описание |
| --- | --- | --- |
| `--users` | `50` | Количество виртуальных пользователей. |
| `--iterations` | `5` | Сколько раз каждый пользователь повторяет сценарий. |
| `--concurrency` | `20` | Максимальное число одновременных обновлений. |
| `--valid-email-ratio` | `0.8` | Доля корректных e-mail среди всех пользователей. |
| `--inter-update-delay` | `0.0` | Задержка (секунды) между обновлениями одного пользователя. |
| `--transport-delay` | `0.0` | Искусственная задержка внутри `FakeBotAPIRequest` (только `synthetic`). |
| `--log-file` | `logs/load_test.log` | Путь к файлу с логами выполнения. |
| `--metrics-file` | `logs/load_test_metrics.json` | Путь к JSON с агрегированными метриками. |
| `--raw-metrics-file` | `—` | При указании сохраняет CSV с покадровыми задержками. |
| `--token` | значение `BOT_TOKEN` из окружения или `TEST:TOKEN` | Токен бота. |
| `--log-level` | `INFO` | Уровень логирования (`DEBUG`, `INFO`, `WARNING`, `ERROR`). |
| `--seed` | `—` | Фиксированный seed генератора случайных чисел для повторяемости сценариев. |
| `--mode` | `synthetic` | Режим тестирования: `synthetic` или `live`. |
| `--scenario` | `full` | Тип сценария: `full`, `simple`, `text_storm`, `menu_spam`, `feedback_loop`. |
| `--profile` | `single` | Преднастроенный профиль нагрузки (`single`, `stress`, `spike`, `soak`). |
| `--chat-ids` | `—` | Список `chat_id` через запятую для режима `live`. |
| `--auto-discover-chat-ids` | `false` | Автоматически пытается извлечь `chat_id` из последних `getUpdates` (только `live`). |
| `--discover-limit` | `20` | Сколько обновлений считывать во время автообнаружения `chat_id`. |
| `--min-duration` | `300.0` | Минимальная длительность теста (секунды) до автоматического завершения. |
| `--max-retries` | `3` | Число повторных попыток при ошибках Bot API. |
| `--live-global-rate` | `25.0` | Глобальный лимит запросов в секунду в `live`-режиме (`0` — без ограничения). |
| `--live-chat-rate` | `1.0` | Лимит запросов в секунду на один чат (`0` — без ограничения). |

### Особенности `live`-режима

* Перед запуском убедитесь, что у бота есть как минимум один активный чат:
  отправьте `/start`, затем используйте `--auto-discover-chat-ids` или передайте
  идентификатор вручную через `--chat-ids`.
* Лимиты `--live-global-rate` и `--live-chat-rate` помогают избежать ошибок
  `Flood control exceeded` (HTTP 429). При получении `RetryAfter` скрипт ждёт
  указанный интервал, делает повтор до `--max-retries` и фиксирует событие в
  отчёте.
* Тайм-ауты `TimedOut` и другие сетевые ошибки автоматически повторяются с
  экспоненциальной паузой. Если после максимума попыток ошибка сохраняется, она
  попадает в раздел `error_messages` итогового JSON.
* Нагрузочное тестирование длится не менее `--min-duration` секунд. После
  истечения времени можно прервать скрипт `Ctrl+C` — он корректно соберёт и
  сохранит накопленные метрики.

## Пример запуска

```bash
python scripts/load_test_bot.py \
  --users 100 \
  --iterations 3 \
  --concurrency 40 \
  --profile stress \
  --scenario menu_spam \
  --valid-email-ratio 0.7 \
  --inter-update-delay 0.02 \
  --transport-delay 0.01 \
  --log-level INFO \
  --log-file logs/load_test.log \
  --metrics-file logs/summary.json \
  --raw-metrics-file logs/raw.csv
```

При выборе профиля `stress` скрипт выполнит четыре фазы с нарастающей
нагрузкой, а отчёты по каждой фазе будут сохранены в файлах с суффиксом
`_<label>`.

## Преднастроенные профили нагрузки

Флаг `--profile` выбирает последовательность фаз и их параметры. Каждая фаза
может изменять количество пользователей, итераций, уровень параллелизма,
сценарий и задержки. Доступны четыре профиля:

* **`single`** — один прогон с указанными параметрами.
* **`stress`** — «прогрев» → базовый уровень → `scale_up` → `breaking_point`.
  В последних двух фазах нагрузка существенно возрастает; в синтетическом
  режиме используется сценарий `menu_spam`, а в live — `text_storm`.
* **`spike`** — базовый прогон, резкий всплеск с очень высокой
  конкурентностью, затем восстановление для оценки поведения после скачка.
* **`soak`** — длительный «soak-тест» с большим числом итераций и финальной
  фазой `chaos`, где повышается доля некорректных e-mail и бот получает серийные
  повторяющиеся запросы.

В многофазном профиле для каждой фазы создаётся отдельный файл метрик и,
при указании `--raw-metrics-file`, отдельный CSV с сырыми задержками. Основной
файл, переданный в `--metrics-file`, содержит агрегированный отчёт вида:

```json
{
  "profile": "stress",
  "phases": [
    {
      "label": "warmup",
      "users": 25,
      "concurrency": 10,
      "scenario": "full",
      "summary": { "total_updates": 123, "...": "..." },
      "metrics_file": "logs/summary_warmup.json",
      "raw_metrics_file": "logs/raw_warmup.csv"
    },
    {
      "label": "breaking_point",
      "users": 200,
      "concurrency": 120,
      "scenario": "menu_spam",
      "summary": { "total_updates": 987, "...": "..." }
    }
  ]
}
```

## Формат отчётных файлов

### CSV с сырыми задержками (`--raw-metrics-file`)

Файл содержит три столбца:

- `update_index` — порядковый номер обработанного обновления;
- `type` — тип обновления (`message`, `callback`, `other`);
- `latency_ms` — длительность обработки в миллисекундах.

Пример строк:

```
update_index,type,latency_ms
1,message,0.206
2,message,0.347
3,callback,0.192
...
```

Каждая строка соответствует одному вызову `Application.process_update`. По
этому файлу удобно строить графики распределения задержек и находить выбросы.

### JSON со сводными метриками (`--metrics-file`)

В JSON записывается словарь со следующими полями:

- `total_updates` — общее количество обработанных обновлений;
- `errors` — число исключений во время обработки;
- `duration_sec` — суммарное время выполнения теста;
- `throughput_rps` — пропускная способность (обновлений в секунду);
- `latency_overall` — агрегированные метрики задержек по всем обновлениям;
- `latency_by_type` — такие же метрики, но для отдельных типов (`message`, `callback`);
- `error_messages` — список текстов исключений (если были).

Для предоставленного примера:

```json
{
  "total_updates": 26,
  "errors": 0,
  "duration_sec": 0.0052,
  "throughput_rps": 5004.62,
  "latency_overall": {
    "avg": 0.000128,
    "median": 0.000120,
    "p95": 0.000203,
    "p99": 0.000312
  },
  "latency_by_type": {
    "message": {
      "avg": 0.000172,
      "median": 0.000143,
      "p95": 0.000312,
      "p99": 0.000340
    },
    "callback": {
      "avg": 0.000115,
      "median": 0.000120,
      "p95": 0.000150,
      "p99": 0.000184
    }
  },
  "error_messages": []
}
```

> Примечание. Для длительных `live`-прогонов поле `duration_sec` будет близко к
> значению `--min-duration`, а `throughput_rps` — ниже из-за встроенного rate
> limiter и повторов после ответов Bot API.

Такие значения говорят о том, что тест завершился без ошибок, обработал 26
обновлений примерно за 5 мс и показал условную пропускную способность ~5000
обновлений в секунду. Задержки находятся в диапазоне 0.09–0.34 мс, причём
сообщения обрабатываются чуть дольше, чем callback-запросы (что логично из-за
валидации e-mail и переходов состояний).

При использовании профилей `stress`, `spike` или `soak` агрегированный файл
(`--metrics-file`) будет содержать список фаз с ссылками на отдельные JSON/CSV
для каждой из них.

### Лог-файл (`--log-file`)

Логи записываются одновременно в консоль и в указанный файл. Если файл пустой,
значит в ходе теста не возникло сообщений на выбранном уровне логирования.
Чтобы увидеть более подробные сообщения, запустите тест с `--log-level DEBUG`.

## Рекомендации по анализу

1. **Сравнивайте метрики разных прогонов.** Фиксируйте `--seed`, чтобы сценарии
   были сопоставимы, и варьируйте параметры нагрузки.
2. **Используйте CSV для построения графиков.** Набросьте гистограммы или
   временные ряды по `latency_ms`, чтобы заметить «хвосты» распределения.
3. **Имитируйте сетевые задержки.** Параметр `--transport-delay` доступен в
   режиме `synthetic` и помогает оценить поведение бота при медленном соединении.
4. **Собирайте логи ошибок.** При появлении записей в `error_messages`
   сопоставьте их с соответствующими строками в CSV и записями журнала.

## Завершение теста

Скрипт сам корректно завершает приложение Telegram (`application.shutdown()`),
поэтому дополнительных действий не требуется. Все файлы отчётов остаются в
указанных путях и готовы к дальнейшему анализу.

## Работа в режиме live

1. Добавьте токен бота в файл `.env` (`BOT_TOKEN=...`) или передайте через
   переменную окружения/флаг `--token`.
2. Определите список тестовых чатов и передайте их идентификаторы с помощью
  `--chat-ids`. Допустимо указать несколько `chat_id`, разделённых запятыми.
  Для индивидуального тестирования достаточно вашего личного диалога с ботом.
  Узнать идентификатор можно двумя способами:

  * автоматическое обнаружение флагом `--auto-discover-chat-ids` (перед запуском
    отправьте боту сообщение `/start`, чтобы обновление попало в очередь);
  * вручную — например, переслать любое сообщение из чата сервису
    [@userinfobot](https://t.me/userinfobot) или посмотреть `chat.id` в логах
    при запуске с `--log-level DEBUG`.

3. Выберите сценарий `simple` или `text_storm` (рекомендуется по умолчанию;
  сценарии `full` и `menu_spam` будут автоматически заменены на `text_storm`,
  поскольку синтетические callback-запросы невалидны для реального Bot API).
4. Запустите тест с `--mode live`. Ответы бота будут отправляться в указанные
  чаты, а задержки и логи будут собраны в тех же файлах, что и в режиме
  `synthetic`.

Если включено автообнаружение, скрипт выведет список найденных `chat_id` в
логах. При повторном запуске их можно указать явно через `--chat-ids`, чтобы
избежать повторного запроса к `getUpdates`.
