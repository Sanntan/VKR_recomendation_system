"""–í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –º–∞—Å—Å–æ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–π —á–µ—Ä–µ–∑ LLM.

–°–∫—Ä–∏–ø—Ç –≤—ã—Å—Ç—É–ø–∞–µ—Ç –≤ —Ä–æ–ª–∏ –æ–±—ë—Ä—Ç–∫–∏ –Ω–∞–¥ —Ñ—É–Ω–∫—Ü–∏—è–º–∏ –∏–∑
``src.recommendation.events.llm_generator`` –∏ –ø–æ–∑–≤–æ–ª—è–µ—Ç –∑–∞–ø—É—Å–∫–∞—Ç—å –∏—Ö
–Ω–µ–ø–æ—Å—Ä–µ–¥—Å—Ç–≤–µ–Ω–Ω–æ –Ω–∞ GPU. –ó–∞ —Å—á—ë—Ç —Ç–æ–≥–æ, —á—Ç–æ ``llm_generator`` –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç
–º–æ–¥–µ–ª–∏ –≤ CUDA-–∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –ø—Ä–∏ –∏–º–ø–æ—Ä—Ç–µ, –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –≤—ã–∑–≤–∞—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É
–º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–π, —á—Ç–æ–±—ã –º–æ–¥–µ–ª–∏ –±—ã–ª–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã–≥—Ä—É–∂–µ–Ω—ã –Ω–∞ –¥–æ—Å—Ç—É–ø–Ω—ã–π GPU.

–ü—Ä–∏–º–µ—Ä –∑–∞–ø—É—Å–∫–∞:

```
python scripts/database_mv/events/run_processing.py \
    --input ./data/events.csv \
    --output ./data/events_processed.json \
    --limit 100
```

–î–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π —Ä–∞–±–æ—Ç—ã —É–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤ –æ–∫—Ä—É–∂–µ–Ω–∏–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
``torch`` (—Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π CUDA), ``unsloth`` –∏ ``sentence-transformers``.
"""

from __future__ import annotations

import argparse
import json
from pathlib import Path
from typing import Iterable, Optional


def parse_args() -> argparse.Namespace:
    """–°—á–∏—Ç—ã–≤–∞–µ—Ç –∞—Ä–≥—É–º–µ–Ω—Ç—ã –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏."""

    parser = argparse.ArgumentParser(description="–û–±—Ä–∞–±–æ—Ç–∫–∞ –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–π –ø—Ä–∏ –ø–æ–º–æ—â–∏ LLM")
    parser.add_argument(
        "--input",
        type=str,
        default="events.csv",
        help="–ü—É—Ç—å –∫ CSV-—Ñ–∞–π–ª—É —Å –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏—è–º–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é events.csv –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å–∫—Ä–∏–ø—Ç–∞)",
    )
    parser.add_argument(
        "--limit",
        type=int,
        default=None,
        help="–û–≥—Ä–∞–Ω–∏—á–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º—ã—Ö –∑–∞–ø–∏—Å–µ–π",
    )
    parser.add_argument(
        "--output",
        type=str,
        default=None,
        help="–ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ JSON. –ï—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω, –¥–∞–Ω–Ω—ã–µ –Ω–µ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è",
    )
    parser.add_argument(
        "--indent",
        type=int,
        default=2,
        help="–û—Ç—Å—Ç—É–ø –¥–ª—è JSON-—Ñ–∞–π–ª–∞ (–∞–∫—Ç—É–∞–ª–µ–Ω —Ç–æ–ª—å–∫–æ –ø—Ä–∏ —É–∫–∞–∑–∞–Ω–∏–∏ --output)",
    )
    return parser.parse_args()


def resolve_path(path: str, default_dir: Path) -> Path:
    """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø—É—Ç—å –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ ``default_dir``."""

    path_obj = Path(path)
    if path_obj.is_absolute():
        return path_obj
    return default_dir / path_obj


def ensure_parent_dir(path: Path) -> None:
    """–°–æ–∑–¥–∞—ë—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Ñ–∞–π–ª–∞, –µ—Å–ª–∏ –æ–Ω–∞ –µ—â—ë –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç."""

    if path.parent.exists():
        return
    path.parent.mkdir(parents=True, exist_ok=True)


def write_results(path: Path, processed: Iterable[dict], indent: int = 2) -> None:
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ JSON."""

    ensure_parent_dir(path)
    with path.open("w", encoding="utf-8") as output_file:
        json.dump(list(processed), output_file, ensure_ascii=False, indent=indent)


def ensure_gpu_environment() -> None:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ GPU –¥–æ –∏–º–ø–æ—Ä—Ç–∞ —Ç—è–∂—ë–ª—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π."""

    try:
        import torch  # –ª–æ–∫–∞–ª—å–Ω—ã–π –∏–º–ø–æ—Ä—Ç, —á—Ç–æ–±—ã –Ω–µ —Ç—è–Ω—É—Ç—å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å –±–µ–∑ –Ω–∞–¥–æ–±–Ω–æ—Å—Ç–∏
    except ImportError as error:  # pragma: no cover - –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –æ–∫—Ä—É–∂–µ–Ω–∏—è
        raise SystemExit(
            "–ù–µ —É–¥–∞–ª–æ—Å—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å torch. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–∞–∫–µ—Ç "
            "torch —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π CUDA."
        ) from error

    if not torch.cuda.is_available():  # pragma: no cover - –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –æ–∫—Ä—É–∂–µ–Ω–∏—è
        raise SystemExit(
            "GPU –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –¥—Ä–∞–π–≤–µ—Ä–æ–≤ –∏ CUDA."
        )


def import_llm_generator():
    """–ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç –º–æ–¥—É–ª—å –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ –∏ –æ–±–æ—Ä–∞—á–∏–≤–∞–µ—Ç –≤–æ–∑–º–æ–∂–Ω—ã–µ –æ—à–∏–±–∫–∏."""

    try:
        from src.recommendation.events import llm_generator
    except ModuleNotFoundError as error:
        raise SystemExit(
            "–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –º–æ–¥—É–ª—å src.recommendation.events.llm_generator."
        ) from error
    except (RuntimeError, NotImplementedError) as error:
        raise SystemExit(
            "–í–æ –≤—Ä–µ–º—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –º–æ–¥–µ–ª–µ–π –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: " f"{error}"
        ) from error

    return llm_generator


def main() -> None:
    args = parse_args()

    script_dir = Path(__file__).resolve().parent
    input_path = resolve_path(args.input, script_dir)

    if not input_path.exists():
        raise FileNotFoundError(
            f"–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ CSV-—Ñ–∞–π–ª —Å –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏—è–º–∏ –ø–æ –ø—É—Ç–∏: {input_path}"
        )

    ensure_gpu_environment()

    generator = import_llm_generator()

    print(f"üì• –ó–∞–≥—Ä—É–∂–∞–µ–º –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏—è –∏–∑: {input_path}")
    events = generator.load_events_csv(str(input_path))
    limit: Optional[int] = args.limit
    if limit is not None and limit <= 0:
        raise ValueError("–ü–∞—Ä–∞–º–µ—Ç—Ä --limit –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–º —á–∏—Å–ª–æ–º")

    print("‚öôÔ∏è  –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É —á–µ—Ä–µ–∑ llm_generator...")
    processed = generator.process_events(events, limit=limit)

    print(f"\n‚úÖ –í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {len(processed)}")

    if args.output:
        output_path = resolve_path(args.output, script_dir)
        write_results(output_path, processed, indent=args.indent)
        print(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_path}")


if __name__ == "__main__":
    main()
