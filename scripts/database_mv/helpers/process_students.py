"""–£—Ç–∏–ª–∏—Ç—ã –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤: –æ–±—Ä–∞–±–æ—Ç–∫–∞ Excel, –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–æ—Ñ–∏–ª–µ–π, –∑–∞–≥—Ä—É–∑–∫–∞ –≤ –ë–î."""
from __future__ import annotations

import json
from pathlib import Path
from typing import Dict, Optional, Any
import pandas as pd

from scripts.database_mv.helpers.data_utils import load_excel
from src.recommendation.students.profile_generator import (
    generate_profile_description,
    vectorize_profiles_batch,
)

# –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π (28 –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π)
# –ü–æ—Ä—è–¥–æ–∫ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –ø–æ—Ä—è–¥–∫—É –≤ Excel —Ñ–∞–π–ª–µ
COMPETENCY_COLUMNS = [
    "–ê–Ω–∞–ª–∏–∑ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏",
    "–ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ",
    "–û—Ä–∏–µ–Ω—Ç–∞—Ü–∏—è –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç",
    "–°—Ç—Ä–µ—Å—Å–æ—É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å",
    "–ü–∞—Ä—Ç–Ω–µ—Ä—Å—Ç–≤–æ/–°–æ—Ç—Ä—É–¥–Ω–∏—á–µ—Å—Ç–≤–æ",
    "–°–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø—Ä–∞–≤–∏–ª–∞–º –∏ –ø—Ä–æ—Ü–µ–¥—É—Ä–∞–º",
    "–°–∞–º–æ—Ä–∞–∑–≤–∏—Ç–∏–µ",
    "–õ–∏–¥–µ—Ä—Å—Ç–≤–æ",
    "–≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç",
    "–ö–ª–∏–µ–Ω—Ç–æ–æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ—Å—Ç—å",
    "–ö–æ–º–º—É–Ω–∏–∫–∞—Ü–∏—è",
    "–ü–∞—Å—Å–∏–≤–Ω—ã–π —Å–ª–æ–≤–∞—Ä–Ω—ã–π –∑–∞–ø–∞—Å",
    "–ê–≤—Ç–æ–Ω–æ–º–∏—è",
    "–ê–ª—å—Ç—Ä—É–∏–∑–º",
    "–í—ã–∑–æ–≤",
    "–ó–∞—Ä–∞–±–æ—Ç–æ–∫",
    "–ö–∞—Ä—å–µ—Ä–∞",
    "–ö—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç—å",
    "–û—Ç–Ω–æ—à–µ–Ω–∏—è",
    "–ü—Ä–∏–∑–Ω–∞–Ω–∏–µ",
    "–ü—Ä–∏–Ω–∞–¥–ª–µ–∂–Ω–æ—Å—Ç—å",
    "–°–∞–º–æ—Ä–∞–∑–≤–∏—Ç–∏–µ.1",
    "–°–º—ã—Å–ª",
    "–°–æ—Ç—Ä—É–¥–Ω–∏—á–µ—Å—Ç–≤–æ",
    "–°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å",
    "–¢—Ä–∞–¥–∏—Ü–∏—è",
    "–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ",
    "–£—Å–ª–æ–≤–∏—è —Ç—Ä—É–¥–∞",
]

# –û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
REQUIRED_COLS = ["ID —É—á–∞—Å—Ç–Ω–∏–∫–∞ –ø—Ä–æ–µ–∫—Ç–∞", "–°–ø–µ—Ü–∏–∞–ª—å–Ω–æ—Å—Ç—å"] + COMPETENCY_COLUMNS


def normalize_competency_value(value) -> Optional[int]:
    """
    –ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏ –∏–∑ Excel.
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è, NaN, —Å—Ç—Ä–æ–∫–∏ –∏ —á–∏—Å–ª–∞.
    
    Args:
        value: –ó–Ω–∞—á–µ–Ω–∏–µ –∏–∑ Excel (–º–æ–∂–µ—Ç –±—ã—Ç—å int, float, str, None, NaN)
    
    Returns:
        –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ (int –æ—Ç 200 –¥–æ 800) –∏–ª–∏ None, –µ—Å–ª–∏ –∑–Ω–∞—á–µ–Ω–∏–µ –ø—Ä–æ–ø—É—â–µ–Ω–æ
    """
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º NaN –∏ None
    if pd.isna(value) or value is None:
        return None
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å—Ç—Ä–æ–∫–∏
    if isinstance(value, str):
        value = value.strip()
        if value in ("-", "", "None", "null", "nan", "NaN"):
            return None
        try:
            score = float(value)
        except (ValueError, TypeError):
            return None
    else:
        try:
            score = float(value)
        except (ValueError, TypeError):
            return None
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å –¥–∏–∞–ø–∞–∑–æ–Ω–∞ (200-800)
    if 200 <= score <= 800:
        return int(round(score))
    else:
        return None


def extract_competencies(row: pd.Series) -> Dict[str, int]:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏ –∏–∑ —Å—Ç—Ä–æ–∫–∏ DataFrame.
    
    Args:
        row: –°—Ç—Ä–æ–∫–∞ DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏ —Å—Ç—É–¥–µ–Ω—Ç–∞
    
    Returns:
        –°–ª–æ–≤–∞—Ä—å {–Ω–∞–∑–≤–∞–Ω–∏–µ_–∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏: —Ç-–±–∞–ª–ª} —Å –≤–∞–ª–∏–¥–Ω—ã–º–∏ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏—è–º–∏
    """
    competencies = {}
    
    for competency_name in COMPETENCY_COLUMNS:
        if competency_name not in row.index:
            continue
        
        value = row[competency_name]
        normalized_value = normalize_competency_value(value)
        
        if normalized_value is not None:
            competencies[competency_name] = normalized_value
    
    return competencies


def process_students_from_excel(
    input_path: Path | str,
    output_path: Path | str,
) -> list[dict[str, Any]]:
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –∏–∑ Excel —Ñ–∞–π–ª–∞ –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ JSON.
    
    Args:
        input_path: –ü—É—Ç—å –∫ –≤—Ö–æ–¥–Ω–æ–º—É Excel —Ñ–∞–π–ª—É
        output_path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è JSON —Ñ–∞–π–ª–∞ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
    
    Returns:
        –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –¥–∞–Ω–Ω—ã–º–∏ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ (ID —É—á–∞—Å—Ç–Ω–∏–∫–∞ –ø—Ä–æ–µ–∫—Ç–∞, –û–ø–∏—Å–∞–Ω–∏–µ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π, –í–µ–∫—Ç–æ—Ä)
    """
    input_path = Path(input_path)
    output_path = Path(output_path)
    
    print("=" * 80)
    print("–û–ë–†–ê–ë–û–¢–ö–ê –î–ê–ù–ù–´–• –°–¢–£–î–ï–ù–¢–û–í")
    print("=" * 80)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –≤—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
    if not input_path.exists():
        raise FileNotFoundError(
            f"‚ùå –§–∞–π–ª {input_path} –Ω–µ –Ω–∞–π–¥–µ–Ω. –ü–æ–º–µ—Å—Ç–∏—Ç–µ Excel —Ñ–∞–π–ª –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é sources/students"
        )
    
    print(f"\nüìÇ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑: {input_path}")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º Excel —Ñ–∞–π–ª
    df = load_excel(input_path, required_cols=REQUIRED_COLS)
    
    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ —Å—Ç—Ä–æ–∫: {len(df)}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤
    missing_cols = [col for col in REQUIRED_COLS if col not in df.columns]
    if missing_cols:
        raise ValueError(f"‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω—ã –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã: {missing_cols}")
    
    # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ —É—á–µ–±–Ω–æ–º—É –∑–∞–≤–µ–¥–µ–Ω–∏—é
    target_institution = '–§–ì–ê–û–£ –í–û "–¢–Æ–ú–ï–ù–°–ö–ò–ô –ì–û–°–£–î–ê–†–°–¢–í–ï–ù–ù–´–ô –£–ù–ò–í–ï–†–°–ò–¢–ï–¢" (–¢—é–º–ì–£)'
    if "–£—á–µ–±–Ω–æ–µ –∑–∞–≤–µ–¥–µ–Ω–∏–µ" in df.columns:
        initial_count = len(df)
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è (—É–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã, –ø—Ä–∏–≤–æ–¥–∏–º –∫ —Å—Ç—Ä–æ–∫–µ)
        df["–£—á–µ–±–Ω–æ–µ –∑–∞–≤–µ–¥–µ–Ω–∏–µ"] = df["–£—á–µ–±–Ω–æ–µ –∑–∞–≤–µ–¥–µ–Ω–∏–µ"].astype(str).str.strip()
        # –§–∏–ª—å—Ç—Ä—É–µ–º: –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫–∏, –≥–¥–µ —É—á–µ–±–Ω–æ–µ –∑–∞–≤–µ–¥–µ–Ω–∏–µ —Ç–æ—á–Ω–æ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å —Ü–µ–ª–µ–≤—ã–º
        df = df[df["–£—á–µ–±–Ω–æ–µ –∑–∞–≤–µ–¥–µ–Ω–∏–µ"] == target_institution]
        filtered_count = len(df)
        removed_count = initial_count - filtered_count
        if removed_count > 0:
            print(f"üîç –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ —É—á–µ–±–Ω–æ–º—É –∑–∞–≤–µ–¥–µ–Ω–∏—é: —É–¥–∞–ª–µ–Ω–æ {removed_count} —Å—Ç—Ä–æ–∫ (–æ—Å—Ç–∞–ª–æ—Å—å {filtered_count})")
        else:
            print(f"üîç –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ —É—á–µ–±–Ω–æ–º—É –∑–∞–≤–µ–¥–µ–Ω–∏—é: –≤—Å–µ —Å—Ç—Ä–æ–∫–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç '{target_institution}'")
    else:
        print(f"‚ö†Ô∏è  –°—Ç–æ–ª–±–µ—Ü '–£—á–µ–±–Ω–æ–µ –∑–∞–≤–µ–¥–µ–Ω–∏–µ' –Ω–µ –Ω–∞–π–¥–µ–Ω, —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø—Ä–æ–ø—É—â–µ–Ω–∞")
    
    # –≠—Ç–∞–ø 1: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –æ–ø–∏—Å–∞–Ω–∏–π
    print(f"\nüîÑ –≠—Ç–∞–ø 1: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –æ–ø–∏—Å–∞–Ω–∏–π...")
    
    student_data = []
    skipped_count = 0
    
    for idx, row in df.iterrows():
        participant_id = row.get("ID —É—á–∞—Å—Ç–Ω–∏–∫–∞ –ø—Ä–æ–µ–∫—Ç–∞")
        specialty = row.get("–°–ø–µ—Ü–∏–∞–ª—å–Ω–æ—Å—Ç—å")
        
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å—Ç—Ä–æ–∫–∏ –±–µ–∑ ID —É—á–∞—Å—Ç–Ω–∏–∫–∞
        if pd.isna(participant_id) or participant_id is None:
            skipped_count += 1
            continue
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º ID –≤ —Å—Ç—Ä–æ–∫—É
        participant_id = str(participant_id).strip()
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏
        competencies = extract_competencies(row)
        
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –±–µ–∑ –≤–∞–ª–∏–¥–Ω—ã—Ö –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π
        if not competencies:
            skipped_count += 1
            continue
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ—Å—Ç—å –≤ —Å—Ç—Ä–æ–∫—É (–µ—Å–ª–∏ –µ—Å—Ç—å)
        specialty_str = None
        if not pd.isna(specialty) and specialty is not None:
            specialty_str = str(specialty).strip()
            if specialty_str == "":
                specialty_str = None
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç–æ–≤–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π
        try:
            profile_description = generate_profile_description(specialty_str, competencies)
            student_data.append({
                "ID —É—á–∞—Å—Ç–Ω–∏–∫–∞ –ø—Ä–æ–µ–∫—Ç–∞": participant_id,
                "–°–ø–µ—Ü–∏–∞–ª—å–Ω–æ—Å—Ç—å": specialty_str,
                "–û–ø–∏—Å–∞–Ω–∏–µ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π": profile_description
            })
        except Exception as e:
            skipped_count += 1
            print(f"   ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ–ø–∏—Å–∞–Ω–∏—è –¥–ª—è —Å—Ç—É–¥–µ–Ω—Ç–∞ {participant_id}: {e}")
            continue
    
    print(f"   ‚úÖ –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ {len(student_data)} —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –¥–ª—è –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏")
    print(f"   ‚è≠Ô∏è  –ü—Ä–æ–ø—É—â–µ–Ω–æ: {skipped_count} —Å—Ç—É–¥–µ–Ω—Ç–æ–≤")
    
    if not student_data:
        print("\n‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
        return []
    
    # –≠—Ç–∞–ø 2: –ë–∞—Ç—á–µ–≤–∞—è –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ)
    print(f"\nüßÆ –≠—Ç–∞–ø 2: –ë–∞—Ç—á–µ–≤–∞—è –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ñ–∏–ª–µ–π...")
    print(f"   –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞: 32")
    print(f"   –í—Å–µ–≥–æ –ø—Ä–æ—Ñ–∏–ª–µ–π –¥–ª—è –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏: {len(student_data)}")
    
    try:
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤—Å–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –æ–ø–∏—Å–∞–Ω–∏—è
        profile_texts = [item["–û–ø–∏—Å–∞–Ω–∏–µ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π"] for item in student_data]
        
        # –í–µ–∫—Ç–æ—Ä–∏–∑—É–µ–º –≤—Å–µ –ø—Ä–æ—Ñ–∏–ª–∏ –±–∞—Ç—á–∞–º–∏
        embeddings = vectorize_profiles_batch(
            profile_texts,
            batch_size=32,
            show_progress_bar=True
        )
        
        print(f"   ‚úÖ –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {len(embeddings)} –≤–µ–∫—Ç–æ—Ä–æ–≤")
        
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –±–∞—Ç—á–µ–≤–æ–π –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏: {e}")
        import traceback
        traceback.print_exc()
        raise
    
    # –≠—Ç–∞–ø 3: –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    print(f"\nüìã –≠—Ç–∞–ø 3: –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...")
    
    results = []
    for i, student_info in enumerate(student_data):
        try:
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º numpy array –≤ —Å–ø–∏—Å–æ–∫ –¥–ª—è JSON
            vector_list = embeddings[i].tolist()
            
            results.append({
                "ID —É—á–∞—Å—Ç–Ω–∏–∫–∞ –ø—Ä–æ–µ–∫—Ç–∞": student_info["ID —É—á–∞—Å—Ç–Ω–∏–∫–∞ –ø—Ä–æ–µ–∫—Ç–∞"],
                "–°–ø–µ—Ü–∏–∞–ª—å–Ω–æ—Å—Ç—å": student_info["–°–ø–µ—Ü–∏–∞–ª—å–Ω–æ—Å—Ç—å"],
                "–û–ø–∏—Å–∞–Ω–∏–µ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π": student_info["–û–ø–∏—Å–∞–Ω–∏–µ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π"],
                "–í–µ–∫—Ç–æ—Ä": vector_list
            })
        except Exception as e:
            print(f"   ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –¥–ª—è —Å—Ç—É–¥–µ–Ω—Ç–∞ {student_info['ID —É—á–∞—Å—Ç–Ω–∏–∫–∞ –ø—Ä–æ–µ–∫—Ç–∞']}: {e}")
            continue
    
    processed_count = len(results)
    
    print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏:")
    print(f"   ‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {processed_count} —Å—Ç—É–¥–µ–Ω—Ç–æ–≤")
    print(f"   ‚è≠Ô∏è  –ü—Ä–æ–ø—É—â–µ–Ω–æ: {skipped_count} —Å—Ç—É–¥–µ–Ω—Ç–æ–≤")
    
    if not results:
        print("\n‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")
        return []
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ JSON —Ñ–∞–π–ª
    print(f"\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤: {output_path}")
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    with output_path.open("w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    print(f"‚úÖ –§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {output_path}")
    
    print(f"\n‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
    print(f"   –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_path}")
    print(f"   –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {len(results)}")
    print(f"   –§–æ—Ä–º–∞—Ç: JSON —Å –ø–æ–ª—è–º–∏: ID —É—á–∞—Å—Ç–Ω–∏–∫–∞ –ø—Ä–æ–µ–∫—Ç–∞, –°–ø–µ—Ü–∏–∞–ª—å–Ω–æ—Å—Ç—å, –û–ø–∏—Å–∞–Ω–∏–µ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π, –í–µ–∫—Ç–æ—Ä")
    
    return results


def load_students_from_json_file(json_path: Path | str) -> list[dict[str, Any]]:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –∏–∑ —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ JSON-—Ñ–∞–π–ª–∞."""
    json_path = Path(json_path)
    
    if not json_path.exists():
        print(f"‚ùå –§–∞–π–ª {json_path} –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        return []
    
    try:
        with json_path.open("r", encoding="utf-8") as f:
            students = json.load(f)
        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(students)} —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –∏–∑ {json_path}")
        return students
    except (json.JSONDecodeError, Exception) as exc:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞ {json_path}: {exc}")
        raise


def insert_students_to_db(
    students: list[dict[str, Any]],
    default_institution: str = "–£–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç",
    batch_size: int = 100,
    limit: int | None = None,
) -> tuple[int, int]:
    """
    –î–æ–±–∞–≤–ª—è–µ—Ç —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –≤ –ë–î, –ø—Ä–æ–ø—É—Å–∫–∞—è –¥—É–±–ª–∏–∫–∞—Ç—ã.
    –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è —Å batch insert –∏ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–æ–π –¥–∞–Ω–Ω—ã—Ö.
    
    Args:
        students: —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –¥–∞–Ω–Ω—ã–º–∏ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤
        default_institution: –Ω–∞–∑–≤–∞–Ω–∏–µ —É—á–µ–±–Ω–æ–≥–æ –∑–∞–≤–µ–¥–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        batch_size: —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è –≤—Å—Ç–∞–≤–∫–∏
        limit: –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è (None = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π)
    
    Returns:
        –∫–æ—Ä—Ç–µ–∂ (–¥–æ–±–∞–≤–ª–µ–Ω–æ, –ø—Ä–æ–ø—É—â–µ–Ω–æ)
    """
    from sqlalchemy.orm import Session
    from sqlalchemy import select
    from src.core.database.connection import engine
    from src.core.database.models import Students, Directions
    
    added_count = 0
    skipped_count = 0
    
    with Session(engine) as db:
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –ª–∏–º–∏—Ç, –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω (—Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π —Å–ø–∏—Å–æ–∫, —á—Ç–æ–±—ã –Ω–µ –∏–∑–º–µ–Ω—è—Ç—å –æ—Ä–∏–≥–∏–Ω–∞–ª)
        original_count = len(students)
        if limit is not None and limit > 0:
            students = list(students[:limit])
            print(f"\nüìä –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫ –≤—Å—Ç–∞–≤–∫–µ {len(students)} —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –∏–∑ {original_count} (–ª–∏–º–∏—Ç: {limit})...")
        else:
            print(f"\nüìä –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫ –≤—Å—Ç–∞–≤–∫–µ {len(students)} —Å—Ç—É–¥–µ–Ω—Ç–æ–≤...")
        
        # –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –∑–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ participant_id –æ–¥–Ω–∏–º –∑–∞–ø—Ä–æ—Å–æ–º
        print("   üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Å—Ç—É–¥–µ–Ω—Ç–æ–≤...")
        existing_participant_ids = set()
        existing_students = db.execute(select(Students.participant_id)).scalars().all()
        existing_participant_ids.update(existing_students)
        print(f"   ‚úÖ –ù–∞–π–¥–µ–Ω–æ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Å—Ç—É–¥–µ–Ω—Ç–æ–≤: {len(existing_participant_ids)}")
        
        # –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –∑–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è –≤ —Å–ª–æ–≤–∞—Ä—å –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
        print("   üîç –ó–∞–≥—Ä—É–∑–∫–∞ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–π...")
        directions_map = {}
        all_directions = db.execute(select(Directions)).scalars().all()
        for direction in all_directions:
            directions_map[direction.title.lower().strip()] = direction.id
        print(f"   ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–π: {len(directions_map)}")
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è batch insert
        students_to_insert = []
        
        print(f"\nüîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤...")
        for i, student_data in enumerate(students, 1):
            try:
                participant_id = student_data.get("ID —É—á–∞—Å—Ç–Ω–∏–∫–∞ –ø—Ä–æ–µ–∫—Ç–∞")
                if not participant_id:
                    skipped_count += 1
                    continue
                
                participant_id = str(participant_id).strip()
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —Å—Ç—É–¥–µ–Ω—Ç
                if participant_id in existing_participant_ids:
                    skipped_count += 1
                    if skipped_count <= 5 or skipped_count % 100 == 0:
                        print(f"   ‚è≠Ô∏è  –ü—Ä–æ–ø—É—â–µ–Ω–æ (–¥—É–±–ª–∏–∫–∞—Ç): {participant_id}")
                    continue
                
                # –ü–æ–ª—É—á–∞–µ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–æ —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ—Å—Ç–∏
                specialty = student_data.get("–°–ø–µ—Ü–∏–∞–ª—å–Ω–æ—Å—Ç—å")
                direction_id = None
                if specialty:
                    specialty_key = str(specialty).strip().lower()
                    direction_id = directions_map.get(specialty_key)
                    if not direction_id:
                        # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –±–µ–∑ —É—á–µ—Ç–∞ —Ä–µ–≥–∏—Å—Ç—Ä–∞ —á–µ—Ä–µ–∑ ilike (–µ—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –≤ –∫—ç—à–µ)
                        from src.core.database.crud.directions import get_direction_by_title
                        direction = get_direction_by_title(db, specialty)
                        if direction:
                            direction_id = direction.id
                            # –î–æ–±–∞–≤–ª—è–µ–º –≤ –∫—ç—à –¥–ª—è —Å–ª–µ–¥—É—é—â–∏—Ö –∏—Ç–µ—Ä–∞—Ü–∏–π
                            directions_map[specialty_key] = direction_id
                
                # –ü–æ–ª—É—á–∞–µ–º –≤–µ–∫—Ç–æ—Ä –ø—Ä–æ—Ñ–∏–ª—è
                profile_embedding = student_data.get("–í–µ–∫—Ç–æ—Ä")
                if not profile_embedding:
                    skipped_count += 1
                    continue
                
                # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤—Å—Ç–∞–≤–∫–∏
                student_dict = {
                    "participant_id": participant_id,
                    "institution": default_institution,
                    "direction_id": direction_id,
                    "profile_embedding": profile_embedding,
                }
                students_to_insert.append(student_dict)
                existing_participant_ids.add(participant_id)  # –î–æ–±–∞–≤–ª—è–µ–º –≤ set, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –≤ –±–∞—Ç—á–µ
                
                # –í—Å—Ç–∞–≤–ª—è–µ–º –±–∞—Ç—á–∞–º–∏
                if len(students_to_insert) >= batch_size:
                    try:
                        db.bulk_insert_mappings(Students, students_to_insert)
                        db.commit()
                        added_count += len(students_to_insert)
                        print(f"   ‚úÖ –í—Å—Ç–∞–≤–ª–µ–Ω–æ –±–∞—Ç—á: {len(students_to_insert)} —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ (–≤—Å–µ–≥–æ: {added_count})")
                        students_to_insert = []
                    except Exception as e:
                        db.rollback()
                        print(f"   ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ batch insert: {e}")
                        # –ü—Ä–æ–±—É–µ–º –≤—Å—Ç–∞–≤–∏—Ç—å –ø–æ –æ–¥–Ω–æ–º—É –∏–∑ —ç—Ç–æ–≥–æ –±–∞—Ç—á–∞
                        for student_dict_single in students_to_insert:
                            try:
                                db.bulk_insert_mappings(Students, [student_dict_single])
                                db.commit()
                                added_count += 1
                            except Exception:
                                db.rollback()
                                skipped_count += 1
                        students_to_insert = []
                
            except Exception as e:
                print(f"   ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å—Ç—É–¥–µ–Ω—Ç–∞ {student_data.get('ID —É—á–∞—Å—Ç–Ω–∏–∫–∞ –ø—Ä–æ–µ–∫—Ç–∞', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}: {e}")
                skipped_count += 1
        
        # –í—Å—Ç–∞–≤–ª—è–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è —Å—Ç—É–¥–µ–Ω—Ç—ã
        if students_to_insert:
            try:
                db.bulk_insert_mappings(Students, students_to_insert)
                db.commit()
                added_count += len(students_to_insert)
                print(f"   ‚úÖ –í—Å—Ç–∞–≤–ª–µ–Ω–æ —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –±–∞—Ç—á: {len(students_to_insert)} —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ (–≤—Å–µ–≥–æ: {added_count})")
            except Exception as e:
                db.rollback()
                print(f"   ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–∏–Ω–∞–ª—å–Ω–æ–º batch insert: {e}")
                # –ü—Ä–æ–±—É–µ–º –≤—Å—Ç–∞–≤–∏—Ç—å –ø–æ –æ–¥–Ω–æ–º—É
                for student_dict_single in students_to_insert:
                    try:
                        db.bulk_insert_mappings(Students, [student_dict_single])
                        db.commit()
                        added_count += 1
                    except Exception:
                        db.rollback()
                        skipped_count += 1
    
    print(f"\nüìä –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    print(f"   ‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ: {added_count}")
    print(f"   ‚è≠Ô∏è  –ü—Ä–æ–ø—É—â–µ–Ω–æ: {skipped_count}")
    
    return added_count, skipped_count

