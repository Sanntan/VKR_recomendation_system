import pandas as pd
import numpy as np
import hdbscan
from sentence_transformers import SentenceTransformer

model = SentenceTransformer("sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")
EMBED_DIM = model.get_sentence_embedding_dimension()

def clusterize_directions(directions: list[str]):
    print(f"üß† –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è {len(directions)} –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–π...")
    embeddings = model.encode(directions, normalize_embeddings=True, show_progress_bar=True)

    print("üîç –ó–∞–ø—É—Å–∫ HDBSCAN –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏...")
    clusterer = hdbscan.HDBSCAN(min_cluster_size=2, min_samples=1, metric="euclidean")
    labels = clusterer.fit_predict(embeddings)

    unique_labels = [lbl for lbl in set(labels) if lbl != -1]
    next_cluster_id = max(unique_labels, default=-1) + 1

    final_labels = []
    for lbl in labels:
        if lbl == -1:
            final_labels.append(next_cluster_id)
            next_cluster_id += 1
        else:
            final_labels.append(lbl)

    print(f"‚úÖ –ü–æ–ª—É—á–µ–Ω–æ {len(set(final_labels))} –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ (–≤–∫–ª—é—á–∞—è –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–µ)")

    df_clusters = pd.DataFrame({
        "–ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ": directions,
        "–ö–ª–∞—Å—Ç–µ—Ä": final_labels,
        "–¢–∏–ø": ["–∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–π" if l >= len(unique_labels) else "–æ—Å–Ω–æ–≤–Ω–æ–π" for l in final_labels]
    })

    return df_clusters, embeddings, final_labels, EMBED_DIM
