# -*- coding: utf-8 -*-
import torch
import pandas as pd
import numpy as np
from unsloth import FastLanguageModel
from sentence_transformers import SentenceTransformer
from src.recommendation.events.utils import format_event_for_db

# === –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è GPU ===
if not torch.cuda.is_available():
    raise RuntimeError("‚ùå GPU –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞. –ü—Ä–æ–≤–µ—Ä—å, —á—Ç–æ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã CUDA –∏ –¥—Ä–∞–π–≤–µ—Ä—ã NVIDIA.")

device = torch.device("cuda")
print(f"‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {torch.cuda.get_device_name(0)}")

# === –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π ===
model_name = "unsloth/Qwen3-4B-Instruct-2507"
print("–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ Qwen3-4B-Instruct —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π GPU...")
model, tokenizer = FastLanguageModel.from_pretrained(
    model_name=model_name,
    max_seq_length=2048,
    load_in_4bit=False,   # True - —ç–∫–æ–Ω–æ–º–∏—è VRAM, False - –ø–æ–ª–Ω—ã–π —Ä–∞–∑–º–µ—Ä
    load_in_8bit=False,
)
model.to(device)
print("‚úÖ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –Ω–∞ GPU")

embedder = SentenceTransformer("paraphrase-multilingual-MiniLM-L12-v2")
embedder.to(device)
print("‚úÖ Sentence-BERT –∑–∞–≥—Ä—É–∂–µ–Ω –Ω–∞ GPU")

# === –û—Å–Ω–æ–≤–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ ===

def load_events_csv(filepath: str):
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å–æ–±—ã—Ç–∏—è –∏–∑ CSV, –ø—Ä–µ–≤—Ä–∞—â–∞—è –∏—Ö –≤ —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π.
    """
    df = pd.read_csv(filepath)
    df = df.where(pd.notnull(df), None)
    return df.to_dict(orient="records")


def generate_short_description(event_info: str) -> str:
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏—è –¥–ª—è Telegram-–∫–∞–Ω–∞–ª–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ event_info.
    """
    system_prompt = """
–¢—ã ‚Äî –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏—è—Ö —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç–∞ –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –¥–ª—è Telegram-–∫–∞–Ω–∞–ª–∞.
–§–æ—Ä–º–∞—Ç –≤—ã–≤–æ–¥–∞:
<2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –±–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞>
–ü–æ–¥–æ–π–¥—ë—Ç —Ç–µ–º, –∫—Ç–æ <–æ–ø–∏—Å–∞–Ω–∏–µ –∞—É–¥–∏—Ç–æ—Ä–∏–∏>
–ü—Ä–∞–≤–∏–ª–∞:
- –¢–æ–ª—å–∫–æ —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫
- –ë–µ–∑ –ø—Ä–∏–≥–ª–∞—à–µ–Ω–∏–π –∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –¥–µ—Ç–∞–ª–µ–π
- –ù–µ –∫–æ–ø–∏—Ä—É–π —Ç–µ–∫—Å—Ç, –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π
- –ö—Ä–∞—Ç–∫–æ, —Å–ø–æ–∫–æ–π–Ω–æ, —Ñ–æ—Ä–º–∞–ª—å–Ω–æ
    """
    messages = [
        {"role": "system", "content": system_prompt.strip()},
        {"role": "user", "content": event_info.strip()},
    ]
    input_ids = tokenizer.apply_chat_template(
        messages, tokenize=True, return_tensors="pt", add_generation_prompt=True
    ).to(device)
    output = model.generate(input_ids=input_ids, max_new_tokens=350, temperature=0.2, top_p=0.9)
    result = tokenizer.decode(output[0], skip_special_tokens=True)
    # –ï—Å–ª–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–æ–¥–µ—Ä–∂–∏—Ç "assistant", —É–¥–∞–ª—è–µ–º –µ–≥–æ
    if "assistant" in result.lower():
        result = result.split("assistant")[-1].strip()
    return result.strip()


def extract_event_dates(event_text: str) -> str:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–∑ —Ç–µ–∫—Å—Ç–∞ –¥–∞—Ç—ã –ø—Ä–æ–≤–µ–¥–µ–Ω–∏—è –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏—è –≤ —Ñ–æ—Ä–º–∞—Ç–µ:
    start_date = DD.MM.YYYY HH:MM
    end_date = DD.MM.YYYY HH:MM
    """
    system_prompt = """
–¢—ã ‚Äî –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π –∏–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∞—Ç—ã –ø—Ä–æ–≤–µ–¥–µ–Ω–∏—è –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏—è –∏–∑ —Ç–µ–∫—Å—Ç–∞.
–§–æ—Ä–º–∞—Ç:
start_date = DD.MM.YYYY HH:MM
end_date = DD.MM.YYYY HH:MM
    """.strip()
    messages = [{"role": "system", "content": system_prompt}, {"role": "user", "content": event_text}]
    input_ids = tokenizer.apply_chat_template(messages, tokenize=True, return_tensors="pt", add_generation_prompt=True).to(device)
    output = model.generate(input_ids=input_ids, max_new_tokens=80, temperature=0.1, top_p=0.9)
    result = tokenizer.decode(output[0], skip_special_tokens=True).strip()
    if "assistant" in result.lower():
        result = result.split("assistant")[-1].strip()
    return result


def detect_event_online(event_text: str) -> str:
    """
    –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ñ–æ—Ä–º–∞—Ç –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏—è: –æ–Ω–ª–∞–π–Ω, –æ—Ñ–ª–∞–π–Ω –∏–ª–∏ –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
    online = True
    online = False
    online = None
    """
    system_prompt = """
–¢—ã ‚Äî –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ñ–æ—Ä–º–∞—Ç –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏—è: –æ–Ω–ª–∞–π–Ω –∏–ª–∏ –æ—Ñ–ª–∞–π–Ω.
–§–æ—Ä–º–∞—Ç:
online = True
online = False
online = None
    """.strip()
    messages = [{"role": "system", "content": system_prompt}, {"role": "user", "content": event_text.strip()}]
    input_ids = tokenizer.apply_chat_template(messages, tokenize=True, return_tensors="pt", add_generation_prompt=True).to(device)
    output = model.generate(input_ids=input_ids, max_new_tokens=30, temperature=0.1, top_p=0.9)
    result = tokenizer.decode(output[0], skip_special_tokens=True).strip()
    if "assistant" in result.lower():
        result = result.split("assistant")[-1].strip()
    return result


def format_event_for_model(event: dict) -> str:
    """
    –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Å–ª–æ–≤–∞—Ä—å –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏—è –≤ —Ç–µ–∫—Å—Ç –¥–ª—è LLM.
    """
    return f"""
Title: {event.get('title', '')}
Description: {event.get('description', '')}
Start date: {event.get('start_date')}
End date: {event.get('end_date')}
Link: {event.get('link', '')}
Format raw: {"Online" if event.get('online') else "Offline" if event.get('online') is not None else "Unknown"}
"""


def format_event_for_date_model(event: dict) -> str:
    """
    –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–µ –¥–ª—è —É—Ç–æ—á–Ω–µ–Ω–∏—è –∏–ª–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞—Ç –¥–ª—è LLM.
    """
    return f"""
Title: {event.get('title', '').strip()}
Description: {event.get('description', '').strip()}
Existing start date: {event.get('start_date')}
Existing end date: {event.get('end_date')}
""".strip()


def format_event_for_online_model(event: dict) -> str:
    """
    –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–µ –¥–ª—è —É—Ç–æ—á–Ω–µ–Ω–∏—è –æ–Ω–ª–∞–π–Ω/–æ—Ñ—Ñ–ª–∞–π–Ω –¥–ª—è LLM.
    """
    return f"""
Title: {event.get('title', '').strip()}
Description: {event.get('description', '').strip()}
Existing online flag: {event.get('online')}
""".strip()


def vectorize_short_description(short_description: str):
    """
    –í–µ–∫—Ç–æ—Ä–∏–∑—É–µ—Ç –∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ (sentence embedding).
    """
    if not short_description or not short_description.strip():
        return None
    embedding = embedder.encode([short_description])[0]
    return np.array(embedding, dtype=float)


def process_events(events, limit=5):
    """
    –ü–æ–ª–Ω–æ—Å—Ç—å—é –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Å–æ–±—ã—Ç–∏—è: –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫–æ—Ä–æ—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ, –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ñ–æ—Ä–º–∞—Ç,
    –∏–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∞—Ç—ã, —Å–æ–∑–¥–∞–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –∏ —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç –ø–æ–ª–Ω—ã–π –æ–±—ä–µ–∫—Ç —Å–æ–±—ã—Ç–∏—è –ø–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ –ë–î.
    
    –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
      events: —Å–ø–∏—Å–æ–∫ –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–π (dict) —Å –ø–æ–ª—è–º–∏: title, link, description, 
              start_date, end_date, image
      limit: –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –ø–æ —á–∏—Å–ª—É –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º—ã—Ö —Å–æ–±—ã—Ç–∏–π
    
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
      List[dict] —Å –ø–æ–ª—è–º–∏ —Å–æ–≥–ª–∞—Å–Ω–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ Events –≤ –ë–î:
      - title, short_description, description, format, start_date, end_date,
        link, image_url, vector_embedding
    """
    processed = []
    total = len(events) if limit is None else min(len(events), limit)
    
    print(f"üöÄ –ù–∞—á–∞–ª–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {total} –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–π...")
    
    for i, event in enumerate(events[:total]):
        try:
            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Å–æ–±—ã—Ç–∏–µ –¥–ª—è LLM
            info = format_event_for_model(event)
            desc_date = format_event_for_date_model(event)
            desc_online = format_event_for_online_model(event)

            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∫–æ—Ä–æ—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ
            short_description = generate_short_description(info)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º/—É—Ç–æ—á–Ω—è–µ–º –¥–∞—Ç—ã
            if not event.get("start_date") or not event.get("end_date"):
                event_dates = extract_event_dates(desc_date)
            else:
                event_dates = f"start_date = {event['start_date']}\nend_date = {event['end_date']}"
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ–æ—Ä–º–∞—Ç (–æ–Ω–ª–∞–π–Ω/–æ—Ñ–ª–∞–π–Ω)
            if event.get("online") in [None, "", "None"]:
                event_online = detect_event_online(desc_online)
            else:
                event_online = f"online = {event['online']}"
            
            # –í–µ–∫—Ç–æ—Ä–∏–∑—É–µ–º –∫–æ—Ä–æ—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ
            vector = vectorize_short_description(short_description)
            
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–º–∏
            event_processed = {
                **event,  # –ò—Å—Ö–æ–¥–Ω—ã–µ –ø–æ–ª—è: title, link, description, start_date, end_date, image
                "short_description": short_description,
                "dates_extracted_raw": event_dates,
                "online_extracted_raw": event_online,
                "embedding": vector.tolist() if vector is not None else None,
            }
            
            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–ª—è –ë–î
            event_for_db = format_event_for_db(event_processed)
            
            processed.append(event_for_db)
            print(f"[{i+1}/{total}] ‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {event.get('title', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')}")
            
        except Exception as e:
            print(f"[{i+1}/{total}] ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ '{event.get('title', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')}': {e}")
            # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–±—ã—Ç–∏–µ —Å –±–∞–∑–æ–≤—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –¥–∞–∂–µ –ø—Ä–∏ –æ—à–∏–±–∫–µ
            event_for_db = format_event_for_db(event)
            processed.append(event_for_db)
    
    print(f"\n‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(processed)} –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–π.")
    return processed
