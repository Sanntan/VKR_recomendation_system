"""–£—Ç–∏–ª–∏—Ç—ã –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–π: –ø–∞—Ä—Å–∏–Ω–≥, —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ, –≤–∞–ª–∏–¥–∞—Ü–∏—è."""
from __future__ import annotations

import json
import re
from datetime import datetime
from pathlib import Path
from typing import Any, Optional, Sequence

import faiss
import numpy as np


def parse_date_string(date_str: str | datetime | Any) -> Optional[datetime]:
    """
    –ü–∞—Ä—Å–∏—Ç –¥–∞—Ç—É –∏–∑ —Å—Ç—Ä–æ–∫–∏ –≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö.
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã:
    - DD.MM.YYYY HH:MM
    - DD.MM.YYYY
    - YYYY-MM-DD HH:MM:SS
    - YYYY-MM-DD
    
    –¢–∞–∫–∂–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç datetime –∏ date –æ–±—ä–µ–∫—Ç—ã.
    """
    if date_str is None:
        return None
    
    # –ï—Å–ª–∏ —É–∂–µ datetime –æ–±—ä–µ–∫—Ç, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å
    if isinstance(date_str, datetime):
        return date_str
    
    # –ï—Å–ª–∏ date –æ–±—ä–µ–∫—Ç, –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ datetime
    from datetime import date
    if isinstance(date_str, date) and not isinstance(date_str, datetime):
        return datetime.combine(date_str, datetime.min.time())
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ pandas Timestamp
    try:
        import pandas as pd
        if isinstance(date_str, pd.Timestamp):
            return date_str.to_pydatetime()
    except ImportError:
        pass
    
    # –ï—Å–ª–∏ –Ω–µ —Å—Ç—Ä–æ–∫–∞, –ø—ã—Ç–∞–µ–º—Å—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤ —Å—Ç—Ä–æ–∫—É
    if not isinstance(date_str, str):
        date_str = str(date_str)
    
    date_str = date_str.strip()
    if not date_str or date_str.lower() in ['none', 'null', 'nan', '']:
        return None
    
    # –§–æ—Ä–º–∞—Ç—ã –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞
    formats = [
        "%d.%m.%Y %H:%M",
        "%d.%m.%Y",
        "%Y-%m-%d %H:%M:%S",
        "%Y-%m-%d",
        "%d/%m/%Y %H:%M",
        "%d/%m/%Y",
    ]
    
    for fmt in formats:
        try:
            return datetime.strptime(date_str, fmt)
        except ValueError:
            continue
    
    # –ü–æ–ø—ã—Ç–∫–∞ –∏–∑–≤–ª–µ—á—å –¥–∞—Ç—É –∏–∑ —Å—Ç—Ä–æ–∫–∏ —Ç–∏–ø–∞ "start_date = DD.MM.YYYY HH:MM"
    match = re.search(r'(\d{1,2}[./]\d{1,2}[./]\d{2,4})(?:\s+(\d{1,2}):(\d{2}))?', date_str)
    if match:
        date_part = match.group(1).replace('/', '.')
        time_part = match.group(2) and match.group(3) and f" {match.group(2)}:{match.group(3)}" or ""
        date_str_clean = date_part + time_part
        for fmt in formats:
            try:
                return datetime.strptime(date_str_clean, fmt)
            except ValueError:
                continue
    
    return None


def parse_dates_from_llm_output(dates_text: str) -> tuple[Optional[datetime], Optional[datetime]]:
    """
    –ü–∞—Ä—Å–∏—Ç –¥–∞—Ç—ã –∏–∑ –≤—ã–≤–æ–¥–∞ LLM –≤ —Ñ–æ—Ä–º–∞—Ç–µ:
    start_date = DD.MM.YYYY HH:MM
    end_date = DD.MM.YYYY HH:MM
    """
    if not dates_text:
        return None, None
    
    start_date = None
    end_date = None
    
    # –ò—â–µ–º start_date
    start_match = re.search(r'start_date\s*=\s*([^\n]+)', dates_text, re.IGNORECASE)
    if start_match:
        start_date = parse_date_string(start_match.group(1))
    
    # –ò—â–µ–º end_date
    end_match = re.search(r'end_date\s*=\s*([^\n]+)', dates_text, re.IGNORECASE)
    if end_match:
        end_date = parse_date_string(end_match.group(1))
    
    return start_date, end_date


def parse_online_from_llm_output(online_text: str) -> Optional[bool]:
    """
    –ü–∞—Ä—Å–∏—Ç –∑–Ω–∞—á–µ–Ω–∏–µ online –∏–∑ –≤—ã–≤–æ–¥–∞ LLM –≤ —Ñ–æ—Ä–º–∞—Ç–µ:
    online = True
    online = False
    online = None
    """
    if not online_text:
        return None
    
    online_text = online_text.strip().lower()
    
    # –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω online = True/False/None
    match = re.search(r'online\s*=\s*(true|false|none|null)', online_text, re.IGNORECASE)
    if match:
        value = match.group(1).lower()
        if value == 'true':
            return True
        elif value == 'false':
            return False
        else:
            return None
    
    # –ï—Å–ª–∏ –ø–∞—Ç—Ç–µ—Ä–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω, –ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
    if 'online' in online_text and 'true' in online_text:
        return True
    elif 'online' in online_text and 'false' in online_text:
        return False
    elif 'offline' in online_text or '–æ—Ñ–ª–∞–π–Ω' in online_text.lower():
        return False
    elif '–æ–Ω–ª–∞–π–Ω' in online_text.lower():
        return True
    
    return None


def format_online_to_string(is_online: Optional[bool]) -> Optional[str]:
    """
    –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç boolean –∑–Ω–∞—á–µ–Ω–∏–µ online –≤ —Å—Ç—Ä–æ–∫—É –¥–ª—è –ø–æ–ª—è format –≤ –ë–î.
    """
    if is_online is True:
        return "–æ–Ω–ª–∞–π–Ω"
    elif is_online is False:
        return "–æ—Ñ–ª–∞–π–Ω"
    else:
        return None


def format_event_for_db(event: dict[str, Any]) -> dict[str, Any]:
    """
    –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Å–æ–±—ã—Ç–∏–µ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –ë–î —Å–æ–≥–ª–∞—Å–Ω–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ Events.
    
    –ò—Å—Ö–æ–¥–Ω—ã–µ –ø–æ–ª—è:
    - title, link, description, start_date, end_date, image
    
    –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –ø–æ–ª—è (–∏–∑ llm_generator):
    - short_description, dates_extracted_raw, online_extracted_raw, embedding
    
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å —Å –ø–æ–ª—è–º–∏ –¥–ª—è –ë–î:
    - title, short_description, description, format, start_date, end_date, 
      link, image_url, vector_embedding
    """
    # –ü–∞—Ä—Å–∏–º –¥–∞—Ç—ã –∏–∑ –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    start_date = None
    end_date = None
    
    if event.get("start_date"):
        start_date = parse_date_string(str(event["start_date"]))
    if event.get("end_date"):
        end_date = parse_date_string(str(event["end_date"]))
    
    # –ï—Å–ª–∏ –¥–∞—Ç—ã –Ω–µ –±—ã–ª–∏ –≤ –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å, 
    # –ø—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å –∏–∑ LLM –≤—ã–≤–æ–¥–∞
    dates_text = event.get("dates_extracted_raw", "")
    if dates_text:
        parsed_start, parsed_end = parse_dates_from_llm_output(dates_text)
        if parsed_start and not start_date:
            start_date = parsed_start
        if parsed_end and not end_date:
            end_date = parsed_end
    
    # –ü–∞—Ä—Å–∏–º online/offline
    is_online = None
    
    # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º –∏—Å—Ö–æ–¥–Ω–æ–µ –ø–æ–ª–µ online
    if "online" in event and event["online"] is not None:
        if isinstance(event["online"], bool):
            is_online = event["online"]
        elif isinstance(event["online"], str):
            online_str = str(event["online"]).strip().lower()
            if online_str in ["true", "1", "yes"]:
                is_online = True
            elif online_str in ["false", "0", "no"]:
                is_online = False
    
    # –ï—Å–ª–∏ –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–∏–ª–∏ –∏–∑ –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö, –ø–∞—Ä—Å–∏–º –∏–∑ LLM –≤—ã–≤–æ–¥–∞
    if is_online is None:
        online_text = event.get("online_extracted_raw", "")
        if online_text:
            is_online = parse_online_from_llm_output(online_text)
    
    format_str = format_online_to_string(is_online)
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    result = {
        "title": safe_strip(event.get("title")) or "",
        "short_description": safe_strip(event.get("short_description")),
        "description": safe_strip(event.get("description")),
        "format": format_str,
        "start_date": start_date.date() if start_date else None,
        "end_date": end_date.date() if end_date else None,
        "link": safe_strip(event.get("link")),
        "image_url": safe_strip(event.get("image")) or safe_strip(event.get("image_url")),
        "vector_embedding": event.get("embedding"),
    }
    
    return result


def save_events_to_json(events: list[dict], output_path: Path, indent: int = 2) -> None:
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å–ø–∏—Å–æ–∫ –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–π –≤ JSON —Ñ–∞–π–ª."""
    output_path = Path(output_path)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –¥–∞—Ç—ã –≤ —Å—Ç—Ä–æ–∫–∏ –¥–ª—è JSON
    events_for_json = []
    for event in events:
        event_copy = event.copy()
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º date –æ–±—ä–µ–∫—Ç—ã –≤ —Å—Ç—Ä–æ–∫–∏
        if event_copy.get("start_date"):
            date_val = event_copy["start_date"]
            if hasattr(date_val, "isoformat"):
                event_copy["start_date"] = date_val.isoformat()
            else:
                event_copy["start_date"] = str(date_val)
        
        if event_copy.get("end_date"):
            date_val = event_copy["end_date"]
            if hasattr(date_val, "isoformat"):
                event_copy["end_date"] = date_val.isoformat()
            else:
                event_copy["end_date"] = str(date_val)
        
        # –£–±–∏—Ä–∞–µ–º –ø–æ–ª—è, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –Ω—É–∂–Ω—ã –≤ –∏—Ç–æ–≥–æ–≤–æ–º JSON (–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –ø–æ–ª—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏)
        event_copy.pop("dates_extracted_raw", None)
        event_copy.pop("online_extracted_raw", None)
        
        events_for_json.append(event_copy)
    
    with output_path.open("w", encoding="utf-8") as f:
        json.dump(events_for_json, f, ensure_ascii=False, indent=indent)
    
    print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(events_for_json)} –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–π –≤ {output_path}")


def validate_event(event: dict[str, Any]) -> tuple[bool, list[str]]:
    """
    –í–∞–ª–∏–¥–∏—Ä—É–µ—Ç –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–µ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç (is_valid, list_of_errors).
    """
    errors = []
    
    if not event.get("title"):
        errors.append("–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –ø–æ–ª–µ 'title'")
    
    return len(errors) == 0, errors


def safe_strip(value: Any) -> Optional[str]:
    """–ë–µ–∑–æ–ø–∞—Å–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Å—Ç—Ä–æ–∫–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è, –≤–∫–ª—é—á–∞—è None."""
    if value is None:
        return None
    if isinstance(value, str):
        return value.strip() or None
    return str(value).strip() or None


def check_event_exists(db, event: dict[str, Any]) -> bool:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–µ –≤ –ë–î.
    –£—á–∏—Ç—ã–≤–∞–µ—Ç –∫–æ–º–±–∏–Ω–∞—Ü–∏—é title + start_date + link –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤.
    
    –õ–æ–≥–∏–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏:
    - –ï—Å–ª–∏ –µ—Å—Ç—å start_date –ò link: –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ title + start_date + link
    - –ï—Å–ª–∏ –µ—Å—Ç—å —Ç–æ–ª—å–∫–æ start_date: –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ title + start_date
    - –ï—Å–ª–∏ –µ—Å—Ç—å —Ç–æ–ª—å–∫–æ link: –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ title + link
    - –ï—Å–ª–∏ –Ω–µ—Ç –Ω–∏ start_date, –Ω–∏ link: –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ç–æ–ª—å–∫–æ –ø–æ title (–¥–ª—è —Ä–µ–≥—É–ª—è—Ä–Ω—ã—Ö –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–π)
    
    Args:
        db: SQLAlchemy —Å–µ—Å—Å–∏—è
        event: —Å–ª–æ–≤–∞—Ä—å —Å –¥–∞–Ω–Ω—ã–º–∏ –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏—è
    
    Returns:
        True –µ—Å–ª–∏ –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–µ —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, False –∏–Ω–∞—á–µ
    """
    from sqlalchemy.orm import Session
    from sqlalchemy import select, and_
    from src.core.database.models import Events
    
    if not isinstance(db, Session):
        raise TypeError("db –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å SQLAlchemy Session")
    
    title = safe_strip(event.get("title")) or ""
    start_date = event.get("start_date")
    link = safe_strip(event.get("link"))
    
    # –ï—Å–ª–∏ –Ω–µ—Ç title, –Ω–µ –º–æ–∂–µ–º –ø—Ä–æ–≤–µ—Ä–∏—Ç—å
    if not title:
        return False
    
    # –°—Ç—Ä–æ–∏–º —É—Å–ª–æ–≤–∏—è –¥–ª—è –ø–æ–∏—Å–∫–∞
    conditions = [Events.title == title]
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –ø—Ä–æ–≤–µ—Ä–∫–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –Ω–∞–ª–∏—á–∏—è –ø–æ–ª–µ–π
    # link —Å—á–∏—Ç–∞–µ—Ç—Å—è –≤–∞–ª–∏–¥–Ω—ã–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –æ–Ω –Ω–µ None –∏ –Ω–µ –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞
    has_link = link is not None and link != ""
    has_start_date = start_date is not None
    
    if has_start_date and has_link:
        # –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø–æ title + start_date + link
        conditions.append(Events.start_date == start_date)
        conditions.append(Events.link == link)
    elif has_start_date:
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ title + start_date
        conditions.append(Events.start_date == start_date)
    elif has_link:
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ title + link
        conditions.append(Events.link == link)
    # –ï—Å–ª–∏ –Ω–µ—Ç –Ω–∏ start_date, –Ω–∏ link - –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ–ª—å–∫–æ –ø–æ title
    # (–¥–ª—è —Ä–µ–≥—É–ª—è—Ä–Ω—ã—Ö –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–π —Å –æ–¥–∏–Ω–∞–∫–æ–≤—ã–º –Ω–∞–∑–≤–∞–Ω–∏–µ–º)
    
    stmt = select(Events).where(and_(*conditions))
    existing = db.scalar(stmt)
    return existing is not None


def process_events_from_csv(
    input_path: Path | str,
    output_path: Path | str,
) -> list[dict[str, Any]]:
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏—è –∏–∑ CSV —á–µ—Ä–µ–∑ LLM –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ JSON."""

    input_path = Path(input_path)
    output_path = Path(output_path)

    if not input_path.exists():
        raise FileNotFoundError(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {input_path}")

    from src.recommendation.events import llm_generator

    print(f"üì• –ó–∞–≥—Ä—É–∑–∫–∞ –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–π –∏–∑: {input_path}")
    raw_events = llm_generator.load_events_csv(str(input_path))

    print(f"‚öôÔ∏è  –û–±—Ä–∞–±–æ—Ç–∫–∞ {len(raw_events)} –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–π —á–µ—Ä–µ–∑ LLM...")
    processed_events = llm_generator.process_events(raw_events)

    print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤: {output_path}")
    save_events_to_json(processed_events, output_path)

    return processed_events


def load_events_from_json_file(output_path: Path | str) -> list[dict[str, Any]]:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏—è –∏–∑ —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ JSON-—Ñ–∞–π–ª–∞."""

    output_path = Path(output_path)

    if not output_path.exists():
        print(f"‚ùå –§–∞–π–ª {output_path} –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        return []

    try:
        with output_path.open("r", encoding="utf-8") as f:
            events = json.load(f)
        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(events)} –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–π –∏–∑ {output_path}")
        return events
    except (json.JSONDecodeError, Exception) as exc:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞ {output_path}: {exc}")
        return []


def _vector_to_array(vector: Any) -> Optional[np.ndarray]:
    """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –≤–µ–∫—Ç–æ—Ä –≤ ndarray —Ñ–æ—Ä–º–∞—Ç–∞ float32."""

    if vector is None:
        return None

    try:
        arr = np.asarray(vector, dtype="float32")
    except Exception:
        return None

    if arr.ndim == 0:
        return None

    if arr.ndim > 1:
        arr = arr.reshape(-1)

    if arr.size == 0:
        return None

    return arr


def _normalize_vector(vector: np.ndarray) -> np.ndarray:
    """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –≤–µ–∫—Ç–æ—Ä –¥–ª—è –∫–æ—Å–∏–Ω—É—Å–Ω–æ–≥–æ —Å—Ö–æ–¥—Å—Ç–≤–∞."""

    norm = np.linalg.norm(vector)
    if norm == 0:
        return vector
    return vector / norm


def _prepare_cluster_index(db) -> tuple[Optional[faiss.IndexFlatIP], list, int]:
    """–ì–æ—Ç–æ–≤–∏—Ç FAISS-–∏–Ω–¥–µ–∫—Å –¥–ª—è —Ü–µ–Ω—Ç—Ä–æ–∏–¥–æ–≤ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤."""

    from sqlalchemy import select
    from src.core.database.models import Clusters

    clusters = (
        db.execute(select(Clusters).where(Clusters.centroid.isnot(None))).scalars().all()
    )

    vectors: list[np.ndarray] = []
    cluster_ids: list = []

    for cluster in clusters:
        array = _vector_to_array(cluster.centroid)
        if array is None:
            continue
        array = _normalize_vector(array)
        if vectors and array.shape[0] != vectors[0].shape[0]:
            print(
                "‚ö†Ô∏è  –ü—Ä–æ–ø—É—â–µ–Ω –∫–ª–∞—Å—Ç–µ—Ä —Å –Ω–µ—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–º —Ä–∞–∑–º–µ—Ä–æ–º –≤–µ–∫—Ç–æ—Ä–∞:",
                cluster.title,
            )
            continue
        vectors.append(array)
        cluster_ids.append(cluster.id)

    if not vectors:
        return None, [], 0

    dim = vectors[0].shape[0]
    index = faiss.IndexFlatIP(dim)
    matrix = np.vstack(vectors)
    index.add(matrix)

    return index, cluster_ids, dim


def _assign_event_clusters(
    db,
    event_id,
    event_title: str,
    event_vector: Sequence[float] | np.ndarray | None,
    index: Optional[faiss.IndexFlatIP],
    cluster_ids: list,
    vector_dim: int,
    top_k: int,
    similarity_threshold: float,
) -> None:
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å–≤—è–∑–∏ –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏—è —Å –±–ª–∏–∂–∞–π—à–∏–º–∏ –∫–ª–∞—Å—Ç–µ—Ä–∞–º–∏."""

    if index is None or not cluster_ids:
        return

    vector_array = _vector_to_array(event_vector)
    if vector_array is None:
        print(f"   ‚ö†Ô∏è  –ù–µ—Ç –≤–µ–∫—Ç–æ—Ä–∞ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–ª–∞—Å—Ç–µ—Ä–æ–≤: {event_title}")
        return

    if vector_array.shape[0] != vector_dim:
        print(
            f"   ‚ö†Ô∏è  –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –≤–µ–∫—Ç–æ—Ä–∞ –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏—è –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å –∫–ª–∞—Å—Ç–µ—Ä–∞–º–∏: {event_title}"
        )
        return

    vector_array = _normalize_vector(vector_array).reshape(1, -1)

    top_k = max(1, min(top_k, len(cluster_ids)))
    similarities, indices = index.search(vector_array, top_k)

    from src.core.database.models import EventClusters

    assigned = 0
    for cluster_idx, similarity in zip(indices[0], similarities[0]):
        if cluster_idx < 0:
            continue
        if similarity < similarity_threshold:
            continue
        db.add(EventClusters(event_id=event_id, cluster_id=cluster_ids[cluster_idx]))
        assigned += 1

    if assigned:
        print(
            f"   üß≠ –ü—Ä–∏–≤—è–∑–∞–Ω–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ ({assigned}): {event_title}"
        )
    else:
        print(
            f"   ‚ö†Ô∏è  –ü–æ–¥—Ö–æ–¥—è—â–∏—Ö –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –ø–æ –ø–æ—Ä–æ–≥—É –¥–ª—è: {event_title}"
        )


def insert_events_to_db(
    events: list[dict[str, Any]],
    *,
    assign_clusters: bool = False,
    cluster_top_k: int = 1,
    similarity_threshold: float = 0.3,
) -> tuple[int, int]:
    """
    –î–æ–±–∞–≤–ª—è–µ—Ç –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏—è –≤ –ë–î, –ø—Ä–æ–ø—É—Å–∫–∞—è –¥—É–±–ª–∏–∫–∞—Ç—ã.

    Args:
        events: —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –¥–∞–Ω–Ω—ã–º–∏ –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–π

    Returns:
        –∫–æ—Ä—Ç–µ–∂ (–¥–æ–±–∞–≤–ª–µ–Ω–æ, –ø—Ä–æ–ø—É—â–µ–Ω–æ)
    """
    from sqlalchemy.orm import Session
    from src.core.database.connection import engine
    from src.core.database.models import Events

    added_count = 0
    skipped_count = 0

    with Session(engine) as db:
        index = None
        cluster_ids: list = []
        vector_dim = 0

        if assign_clusters:
            index, cluster_ids, vector_dim = _prepare_cluster_index(db)
            if index is None:
                print("‚ö†Ô∏è  –ö–ª–∞—Å—Ç–µ—Ä—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –∏–ª–∏ –±–µ–∑ —Ü–µ–Ω—Ç—Ä–æ–∏–¥–æ–≤. –ü—Ä–∏–≤—è–∑–∫–∞ –ø—Ä–æ–ø—É—â–µ–Ω–∞.")

        for i, event in enumerate(events, 1):
            try:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–µ
                if check_event_exists(db, event):
                    skipped_count += 1
                    if i <= 5 or i % 10 == 0:
                        print(f"   ‚è≠Ô∏è  –ü—Ä–æ–ø—É—â–µ–Ω–æ (–¥—É–±–ª–∏–∫–∞—Ç): {event.get('title', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')}")
                    continue

                # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º vector_embedding
                vector_embedding = event.get("vector_embedding")
                # –ï—Å–ª–∏ —ç—Ç–æ —Å–ø–∏—Å–æ–∫, –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Ñ–æ—Ä–º–∞—Ç –¥–ª—è pgvector
                # pgvector –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç —Å–ø–∏—Å–æ–∫ –≤ Vector –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏

                # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤–æ–µ –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–µ
                new_event = Events(
                    title=event.get("title", ""),
                    short_description=event.get("short_description"),
                    description=event.get("description"),
                    format=event.get("format"),
                    start_date=event.get("start_date"),
                    end_date=event.get("end_date"),
                    link=event.get("link"),
                    image_url=event.get("image_url"),
                    vector_embedding=vector_embedding,  # pgvector –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∞–µ—Ç —Å–ø–∏—Å–æ–∫
                )

                db.add(new_event)
                db.flush()

                if assign_clusters and index is not None and cluster_ids:
                    _assign_event_clusters(
                        db,
                        new_event.id,
                        event.get("title", "–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è"),
                        vector_embedding,
                        index,
                        cluster_ids,
                        vector_dim,
                        cluster_top_k,
                        similarity_threshold,
                    )

                db.commit()
                db.refresh(new_event)

                added_count += 1
                if added_count <= 5 or added_count % 10 == 0:
                    print(f"   ‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ –≤ –ë–î: {event.get('title', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')}")

            except Exception as e:
                db.rollback()
                print(f"   ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ '{event.get('title', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')}': {e}")
                skipped_count += 1
    
    return added_count, skipped_count

